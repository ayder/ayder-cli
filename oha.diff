diff --git a/CLAUDE.md b/CLAUDE.md
index f99c3ad..a8099ce 100644
--- a/CLAUDE.md
+++ b/CLAUDE.md
@@ -82,7 +82,9 @@ Example:
 ```
 
 **Test Structure** (615+ tests, 96% coverage):
-- `test_client.py` - ChatSession, Agent classes, and main chat loop
+- `test_client.py` - ChatSession, Agent classes
+- `test_chat_loop.py` - ChatLoop, IterationController, ToolCallHandler, CheckpointManager
+- `test_checkpoint_manager.py` - CheckpointManager for checkpoint/restore cycles
 - `test_cli_file_stdin.py` - CLI file/stdin handling, piped input auto-detection, command mode
 - `test_cli_tui.py` - CLI TUI flag integration
 - `test_commands.py` - Slash commands (/help, /tools, etc.)
@@ -90,7 +92,8 @@ Example:
 - `test_config_coverage.py` - Extended config validation coverage
 - `test_diff_preview.py` - Diff generation and preview
 - `test_main.py` - Entry point (__main__)
-- `test_memory.py` - Cross-session memory tools (save_memory, load_memory)
+- `test_memory.py` - Cross-session memory tools (save_memory, load_memory) in `memory.py`
+- `test_checkpoint_manager.py` - Checkpoint management in `checkpoint_manager.py`
 - `test_notes.py` - Note creation functionality
 - `test_process_manager.py` - Background process management (ProcessManager, 4 tool functions, config validation)
 - `test_parameter_aliasing.py` - Tool parameter normalization
@@ -113,13 +116,36 @@ All tests use pytest fixtures and mocking (no live LLM calls required).
 
 The application is organized into several modules:
 
-- **`src/ayder_cli/client.py`** — Main chat loop, `ChatSession` class, and `Agent` class. Contains `call_llm_async()` for async LLM calls (used by the TUI). The `ChatSession` class manages conversation state, history, user input via prompt-toolkit (emacs keybindings, persistent history at `~/.ayder_chat_history`). The `get_input()` method displays a cyan `❯` prompt. The `Agent` class handles the agentic loop (up to 10 consecutive tool calls per user message, configurable with `-I`). Supports both standard OpenAI tool calls and custom XML-parsed calls. Slash commands are delegated to `handle_command()` from `commands/`.
+- **`src/ayder_cli/client.py`** — `ChatSession` class, `Agent` class, and `call_llm_async()` for async LLM calls (used by the TUI). The `ChatSession` class manages conversation state, history, user input via prompt-toolkit (emacs keybindings, persistent history at `~/.ayder_chat_history`). The `get_input()` method displays a cyan `❯` prompt. The `Agent` class delegates to `ChatLoop` for the agentic loop. Supports both standard OpenAI tool calls and custom XML-parsed calls. Slash commands are delegated to `handle_command()` from `commands/`.
 
-- **`src/ayder_cli/cli.py`** — Command-line interface with argparse. Handles CLI flags (`--version`, `--tui`, `-f/--file`, `--stdin`), direct command execution (non-interactive mode), and auto-detection of piped input. The `_build_services()` composition root creates a `ProcessManager` and passes it to `create_default_registry()`, then returns a 5-tuple `(config, llm_provider, tool_executor, project_ctx, enhanced_system)` — the system prompt is enhanced with the project structure macro. `run_interactive()` and `run_command()` pass the enhanced prompt to `ChatSession`. Supports Unix-style piping: `echo "create test.py" | ayder` auto-enables stdin mode without requiring `--stdin` flag.
+- **`src/ayder_cli/chat_loop.py`** — **Core chat loop logic** with separated concerns:
+  - `ChatLoop` — Orchestrates the agentic conversation loop, manages iteration counting, memory checkpoints, and tool execution
+  - `IterationController` — Manages iteration counting and triggers memory checkpoints when limits are reached
+  - `ToolCallHandler` — Parses and executes tool calls (both standard OpenAI and custom XML)
+  - `CheckpointManager` — Creates memory checkpoints by asking LLM to summarize and resets conversation context
+  - `LoopConfig` — Configuration dataclass for loop parameters (max_iterations, model, permissions, etc.)
+  - Memory checkpoint cycle: When iteration limit reached → Ask LLM to write summary → Reset conversation → Load memory → Continue with fresh context (prevents context window overflow)
 
-- **`src/ayder_cli/prompts.py`** — System prompts and prompt templates. Contains `SYSTEM_PROMPT` and `PLANNING_PROMPT` (for task creation). Both are enhanced with project structure at startup via `_build_services()`.
+- **`src/ayder_cli/checkpoint_manager.py`** — **Checkpoint management**. `CheckpointManager` class handles saving/loading conversation summaries to `.ayder/memory/current_memory.md`. Used by `ChatLoop` to prevent "content rotting" during long-running tasks. Tracks checkpoint cycles and provides prompt builders (`build_checkpoint_prompt()`, `build_restore_prompt()`, `build_quick_restore_message()`). All prompt templates imported from `prompts.py` (no hardcoded prompts).
 
-- **`src/ayder_cli/commands/`** — Command registry system for slash commands. Uses a class-based registry pattern (`@register_command` decorator on `BaseCommand` subclasses). The `handle_command()` function dispatches to registered handlers with a `SessionContext` dataclass. 14 commands registered: `/help`, `/tools`, `/tasks`, `/task-edit`, `/implement`, `/implement-all`, `/edit`, `/verbose`, `/clear`, `/compact`, `/summary`, `/load`, `/undo`, `/plan`.
+- **`src/ayder_cli/cli.py`** — CLI entry point with argument parsing. Handles CLI flags (`--version`, `--tui`, `-f/--file`, `--stdin`, `-I/--iterations`), auto-detection of piped input, and delegates execution to `cli_runner.py`. Supports Unix-style piping: `echo "create test.py" | ayder` auto-enables stdin mode without requiring `--stdin` flag. Contains only `create_parser()` and `read_input()` — all execution logic moved to `cli_runner.py`.
+
+- **`src/ayder_cli/cli_runner.py`** — **CLI execution logic** with separated concerns:
+  - `_build_services()` — Composition root that creates `ProcessManager` and `CheckpointManager`, returns 6-tuple `(config, llm_provider, tool_executor, project_ctx, enhanced_system, checkpoint_manager)`. Enhances system prompt with project structure macro.
+  - `InteractiveRunner` — Runner class for REPL mode (`run_interactive()`). Manages session lifecycle, command dispatch, and agent interaction loop.
+  - `CommandRunner` — Runner class for single command execution (`run_command()`). Executes one prompt and exits.
+  - `TaskRunner` — Runner class for task CLI operations (`--tasks`, `--implement`, `--implement-all`).
+  - Clean separation: CLI parsing (cli.py) → Execution (cli_runner.py) → Core logic (client.py/chat_loop.py)
+
+- **`src/ayder_cli/prompts.py`** — **Centralized prompt templates** organized by usage. Each prompt has a REASON comment explaining why the LLM is being prompted:
+  - **Core prompts**: `SYSTEM_PROMPT` — defines AI role and capabilities
+  - **Project structure**: `PROJECT_STRUCTURE_MACRO_TEMPLATE` — provides codebase overview at startup so LLM knows what files exist
+  - **Task planning**: `PLANNING_PROMPT_TEMPLATE` — transforms high-level requests into actionable tasks
+  - **Task execution**: `TASK_EXECUTION_PROMPT_TEMPLATE`, `TASK_EXECUTION_ALL_PROMPT_TEMPLATE` — implements specific or all pending tasks
+  - **Conversation management**: `CLEAR_COMMAND_RESET_PROMPT`, `SUMMARY_COMMAND_PROMPT_TEMPLATE`, `LOAD_MEMORY_COMMAND_PROMPT_TEMPLATE`, `COMPACT_COMMAND_PROMPT_TEMPLATE` — manage conversation state
+  - **Memory checkpoints**: `MEMORY_CHECKPOINT_PROMPT_TEMPLATE`, `MEMORY_RESTORE_PROMPT_TEMPLATE`, `MEMORY_QUICK_RESTORE_MESSAGE_TEMPLATE`, `MEMORY_NO_MEMORY_MESSAGE` — automatic checkpoint/restore at iteration limits
+
+- **`src/ayder_cli/commands/`** — Command registry system for slash commands. Uses a class-based registry pattern (`@register_command` decorator on `BaseCommand` subclasses). The `handle_command()` function dispatches to registered handlers with a `SessionContext` dataclass. 14 commands registered: `/help`, `/tools`, `/tasks`, `/task-edit`, `/implement`, `/implement-all`, `/edit`, `/verbose`, `/clear`, `/compact`, `/summary`, `/load`, `/undo`, `/plan`. `commands/system.py` imports all prompt templates from `prompts.py` (no hardcoded prompts).
 
 - **`src/ayder_cli/parser.py`** — Enhanced XML tool call parser. Handles standard format (`<function=name><parameter=key>value</parameter></function>`), lazy format for single-param tools (`<function=name>value</function>` with parameter name inference via `_infer_parameter_name()`), and returns `{"error": "message"}` objects for malformed input.
 
@@ -165,14 +191,14 @@ Entry points:
 - **CLI**: `ayder_cli.cli:main` (registered as the `ayder` CLI script in pyproject.toml)
 - **Legacy/TUI**: `ayder_cli.client:run_chat` (can be called directly for programmatic use)
 
-### ChatSession and Agent Classes
+### ChatSession, Agent, and ChatLoop Classes
 
-The `client.py` module implements two core classes extracted from the original monolithic `run_chat()`:
+The `client.py` module implements two core classes, delegating loop logic to `chat_loop.py`:
 
 **ChatSession** — Manages conversation state, history, and user input:
 ```python
 class ChatSession:
-    def __init__(self, config, system_prompt, permissions=None, iterations=10)
+    def __init__(self, config, system_prompt, permissions=None, iterations=50, checkpoint_manager=None)
     def start()                        # Initialize prompt session, print banner
     def add_message(role, content, **kwargs)
     def append_raw(message)            # Append pre-formed message (e.g., tool_calls)
@@ -182,16 +208,38 @@ class ChatSession:
     def render_history()               # Debug display
 ```
 
-**Agent** — Handles LLM API interaction and the agentic tool execution loop:
+**Agent** — High-level interface that delegates to `ChatLoop`:
 ```python
 class Agent:
     def __init__(self, llm_provider: LLMProvider, tools: ToolExecutor, session: ChatSession)
-    def chat(user_input) -> str | None  # Main agentic loop
+    def chat(user_input) -> str | None  # Delegates to ChatLoop.run()
+```
+
+**ChatLoop** — Orchestrates the agentic conversation loop (in `chat_loop.py`):
+```python
+class ChatLoop:
+    def __init__(self, llm_provider, tool_executor, session, config: LoopConfig, checkpoint_manager=None)
+    def run(user_input) -> str | None   # Main loop with memory checkpoint support
+    
+# Supporting classes:
+class IterationController:    # Manages iteration counting and checkpoint triggers
+class ToolCallHandler:        # Parses and executes tool calls
+class CheckpointManager:      # Creates/restores memory checkpoints
 ```
 
+**Memory Checkpoint Cycle:**
+The `-I/--iterations` flag sets a high-watermark for automatic memory checkpoints. When the iteration limit is reached:
+1. `CheckpointManager` asks the LLM to summarize the conversation
+2. Summary is saved to `.ayder/memory/current_memory.md`
+3. Conversation is reset (keeping only system prompt)
+4. Memory is loaded back as a user message
+5. Iteration counter resets to 0, allowing the agent to continue with fresh context
+
+This prevents "content rotting" in long-running tasks while maintaining task continuity.
+
 ### Tools Package Details
 
-The `tools/` package follows a modular architecture with clear separation of concerns:
+The `tools/` package and `chat_loop.py` follow a modular architecture with clear separation of concerns:
 
 **Import Paths:**
 ```python
@@ -242,7 +290,7 @@ path = ctx.validate_path("../../etc/passwd")  # Raises ValueError (traversal blo
 relative = ctx.to_relative(absolute_path)     # Convert back to relative string
 ```
 
-**Integration:** At startup, `cli.py:_build_services()` creates a `ProjectContext` and injects it into `ToolRegistry` and `ToolExecutor` via constructor arguments. The `prepare_new_content()` utility accepts an optional `project_ctx` parameter for path resolution.
+**Integration:** At startup, `cli.py:_build_services()` creates a `ProjectContext` and `MemoryManager`, then injects them into `ToolRegistry`, `ToolExecutor`, and `ChatSession` via constructor arguments. The `prepare_new_content()` utility accepts an optional `project_ctx` parameter for path resolution.
 
 ### Command Registry Pattern
 
@@ -355,7 +403,7 @@ The TUI (`tui.py`) provides an alternative dashboard interface built with Textua
 
 - **CLI with Piped Input Auto-Detection**: The CLI automatically detects piped input (e.g., `echo "text" | ayder`) by checking `sys.stdin.isatty()`. When stdin is piped and no explicit mode flags are set (`--file`, `--stdin`, `--tui`), the CLI auto-enables stdin mode, matching behavior of standard Unix tools. Explicit `--stdin` flag still supported for backwards compatibility.
 
-- **Modular Tools Package**: The `tools/` package provides a clean separation with `impl.py` (10 core tool implementations), `schemas.py` (definitions), `registry.py` (execution + middleware + callbacks + DI), `definition.py` (ToolDefinition dataclass), and `utils.py` (helpers). Additional tool modules `notes.py`, `memory.py`, `process_manager.py`, and `tasks.py` provide specialized functionality (3 memory/note tools, 4 background process tools, 2 task management tools). 20 tools total.
+- **Modular Tools and Chat Loop**: The `tools/` package provides clean separation with `impl.py` (10 core tool implementations), `schemas.py` (definitions), `registry.py` (execution + middleware + callbacks + DI), `definition.py` (ToolDefinition dataclass), and `utils.py` (helpers). The `chat_loop.py` module separates iteration management, tool handling, and memory checkpoints from `client.py`. Additional modules `notes.py`, `memory.py`, `checkpoint_manager.py`, `process_manager.py`, and `tasks.py` provide specialized functionality (3 memory/note tools, 4 background process tools, 2 task management tools, checkpoint management). 20 tools total.
 
 - **Planning Mode**: Activated via `/plan` command. Injects `PLANNING_PROMPT` as a user message to guide the LLM to act as a "Task Master" for task creation.
 
diff --git a/README.md b/README.md
index f579bee..583d7aa 100644
--- a/README.md
+++ b/README.md
@@ -496,6 +496,26 @@ src/ayder_cli/
     utils.py       -- Tool utilities (content preparation for diffs)
 ```
 
+### Prompt Organization
+
+All prompt templates are centralized in `src/ayder_cli/prompts.py`. Each prompt includes a REASON comment explaining why the LLM is being prompted:
+
+| Prompt | Used By | REASON |
+|--------|---------|--------|
+| `SYSTEM_PROMPT` | `cli_runner.py` | Define AI role, operational principles, reasoning workflow, and available capabilities |
+| `PROJECT_STRUCTURE_MACRO_TEMPLATE` | `cli_runner.py` | Provide codebase overview at startup so LLM knows what files exist |
+| `PLANNING_PROMPT_TEMPLATE` | `commands/system.py` | Transform high-level requests into actionable tasks with acceptance criteria |
+| `TASK_EXECUTION_PROMPT_TEMPLATE` | `cli_runner.py` | Instruct LLM to implement a specific task and mark it complete |
+| `TASK_EXECUTION_ALL_PROMPT_TEMPLATE` | `cli_runner.py` | Process all pending tasks sequentially without stopping between tasks |
+| `CLEAR_COMMAND_RESET_PROMPT` | `commands/system.py` | Confirm LLM understands context is fresh after `/clear` |
+| `SUMMARY_COMMAND_PROMPT_TEMPLATE` | `commands/system.py` | Extract key decisions from conversation to memory file |
+| `LOAD_MEMORY_COMMAND_PROMPT_TEMPLATE` | `commands/system.py` | Restore context from saved memory to continue previous work |
+| `COMPACT_COMMAND_PROMPT_TEMPLATE` | `commands/system.py` | Combine summary/save/clear/reload to prevent context window overflow |
+| `MEMORY_CHECKPOINT_PROMPT_TEMPLATE` | `checkpoint_manager.py` | Force LLM to save progress before automatic context reset at iteration limit |
+| `MEMORY_RESTORE_PROMPT_TEMPLATE` | `checkpoint_manager.py` | Instruct LLM to read saved memory after checkpoint reset |
+| `MEMORY_QUICK_RESTORE_MESSAGE_TEMPLATE` | `checkpoint_manager.py` | Include saved memory directly for immediate restoration after reset |
+| `MEMORY_NO_MEMORY_MESSAGE` | `checkpoint_manager.py` | Fallback when no memory was saved before checkpoint reset |
+
 ## License
 
 MIT
diff --git a/pyproject.toml b/pyproject.toml
index 19e6a3d..92ba4fe 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -4,7 +4,7 @@ build-backend = "hatchling.build"
 
 [project]
 name = "ayder-cli"
-version = "0.85.1"
+version = "0.86.0"
 description = "Interactive AI agent chat client for local LLMs"
 readme = "README.md"
 requires-python = ">=3.12"
diff --git a/src/ayder_cli/banner.py b/src/ayder_cli/banner.py
index 6902d22..0c95eb7 100644
--- a/src/ayder_cli/banner.py
+++ b/src/ayder_cli/banner.py
@@ -12,10 +12,12 @@ from ayder_cli.console import console
 
 TIPS = [
     "Use /help for available commands",
-    "Ctrl+R to search command history",
     "Use /tools to see available tools",
     "Use /compact to summarize, save, and reset",
-    "Use /undo to remove last exchange",
+    "Use /model to change LLM model",
+    "Use /plan type your plan to split into small PRD files",
+    "Use /tasks to list current tasks",
+    "Use /implement N to implement the task (N = 1 on TASK-001)",
 ]
 
 GOTHIC_A = [
@@ -301,6 +303,124 @@ def print_futuristic_banner():
 """)
 
 
+def _hex_to_rgb(h: str) -> tuple[int, int, int]:
+    """Convert hex color string to RGB tuple."""
+    h = h.lstrip("#")
+    return int(h[0:2], 16), int(h[2:4], 16), int(h[4:6], 16)
+
+
+def _lerp_color(c1: str, c2: str, t: float) -> str:
+    """Linearly interpolate between two hex colors."""
+    r1, g1, b1 = _hex_to_rgb(c1)
+    r2, g2, b2 = _hex_to_rgb(c2)
+    r = int(r1 + (r2 - r1) * t)
+    g = int(g1 + (g2 - g1) * t)
+    b = int(b1 + (b2 - b1) * t)
+    return f"#{r:02x}{g:02x}{b:02x}"
+
+
+def _gradient_at(position: float, stops: list[str]) -> str:
+    """Get color at position (0.0-1.0) along a list of gradient stops."""
+    position = max(0.0, min(1.0, position))
+    if position >= 1.0:
+        return stops[-1]
+    segment = position * (len(stops) - 1)
+    i = int(segment)
+    t = segment - i
+    return _lerp_color(stops[i], stops[min(i + 1, len(stops) - 1)], t)
+
+
+def create_tui_banner(model: str = "default", ver: str = None) -> Text:
+    """
+    Create a colorful futuristic banner for the TUI.
+
+    Returns a Rich Text object with a horizontal neon gradient across
+    block-letter ASCII art.  Designed to be mounted as the first Static
+    widget inside a scrollable ChatView so it scrolls away naturally.
+    """
+    ver = ver or __version__
+
+    art = [
+        "  █████╗ ██╗   ██╗██████╗ ███████╗██████╗  ",
+        " ██╔══██╗╚██╗ ██╔╝██╔══██╗██╔════╝██╔══██╗ ",
+        " ███████║ ╚████╔╝ ██║  ██║█████╗  ██████╔╝ ",
+        " ██╔══██║  ╚██╔╝  ██║  ██║██╔══╝  ██╔══██╗ ",
+        " ██║  ██║   ██║   ██████╔╝███████╗██║  ██║ ",
+        " ╚═╝  ╚═╝   ╚═╝   ╚═════╝ ╚══════╝╚═╝  ╚═╝ ",
+    ]
+
+    # Neon gradient:  cyan ➜ electric blue ➜ indigo ➜ purple ➜ magenta ➜ hot pink
+    gradient = [
+        "#00e5ff",
+        "#00b0ff",
+        "#2979ff",
+        "#5c6bc0",
+        "#7c4dff",
+        "#aa00ff",
+        "#d500f9",
+        "#f50057",
+    ]
+
+    # Vertical brightness multipliers (top=bright, bottom fades slightly)
+    row_brightness = [1.0, 0.95, 0.90, 0.85, 0.80, 0.70]
+
+    banner = Text()
+    banner.append("\n")
+
+    max_width = max(len(line) for line in art)
+
+    for row_idx, line in enumerate(art):
+        brightness = row_brightness[row_idx] if row_idx < len(row_brightness) else 0.7
+        for col_idx, ch in enumerate(line):
+            if ch in (" ", "\t"):
+                banner.append(ch)
+            else:
+                pos = col_idx / max(max_width - 1, 1)
+                base = _gradient_at(pos, gradient)
+                # Apply brightness (scale RGB toward 0)
+                r, g, b = _hex_to_rgb(base)
+                r = int(r * brightness)
+                g = int(g * brightness)
+                b = int(b * brightness)
+                banner.append(ch, style=f"bold #{r:02x}{g:02x}{b:02x}")
+        banner.append("\n")
+
+    # Thin separator
+    banner.append("\n")
+    sep = "  " + "─" * (max_width - 2)
+    for i, ch in enumerate(sep):
+        if ch == "─":
+            pos = i / max(len(sep) - 1, 1)
+            color = _gradient_at(pos, gradient)
+            # Dim the separator
+            r, g, b = _hex_to_rgb(color)
+            banner.append(ch, style=f"#{r // 3:02x}{g // 3:02x}{b // 3:02x}")
+        else:
+            banner.append(ch)
+    banner.append("\n\n")
+
+    # Tagline
+    banner.append("  ")
+    banner.append("◆ ", style="bold #00e5ff")
+    banner.append("AI Agent  ", style="italic #7c7c9a")
+    banner.append("for ", style="italic #555570")
+    banner.append("Development ", style="italic #5cb870")
+    banner.append("& ", style="italic #555570")
+    banner.append("Reasoning", style="italic #d4a043")
+    banner.append("\n")
+
+    # Info line
+    banner.append("    ")
+    banner.append(f"v{ver}", style="bold #5cb870")
+    banner.append("  ·  ", style="#555570")
+    banner.append(model, style="#5eaff5")
+    banner.append("  ·  ", style="#555570")
+    banner.append("sandboxed", style="#666680")
+    banner.append("\n\n")
+
+    return banner
+
+
 if __name__ == "__main__":
     import sys
     
@@ -319,6 +439,8 @@ if __name__ == "__main__":
             print_futuristic_banner()
         elif arg == "--rich":
             print_rich_banner()
+        elif arg == "--tui":
+            console.print(create_tui_banner("qwen3-coder:latest"))
         else:
             print_welcome_banner("qwen2.5-coder:14b", str(Path.cwd()))
     else:
diff --git a/src/ayder_cli/cli.py b/src/ayder_cli/cli.py
index f02c8a5..00b9963 100644
--- a/src/ayder_cli/cli.py
+++ b/src/ayder_cli/cli.py
@@ -1,3 +1,8 @@
+"""CLI entry point for ayder.
+
+This module handles argument parsing and delegates to cli_runner.py for execution.
+"""
+
 import argparse
 import sys
 from pathlib import Path
@@ -137,231 +142,13 @@ def read_input(args) -> str:
         return None
 
 
-def _build_services(config=None, project_root="."):
-    """Build the service dependency graph (Composition Root).
-
-    Returns:
-        Tuple of (config, llm_provider, tool_executor, project_ctx, enhanced_system)
-    """
-    from ayder_cli.core.config import load_config
-    from ayder_cli.core.context import ProjectContext
-    from ayder_cli.services.llm import OpenAIProvider
-    from ayder_cli.services.tools.executor import ToolExecutor
-    from ayder_cli.tools.registry import create_default_registry
-    from ayder_cli.process_manager import ProcessManager
-    from ayder_cli.prompts import SYSTEM_PROMPT
-
-    cfg = config or load_config()
-    llm_provider = OpenAIProvider(base_url=cfg.base_url, api_key=cfg.api_key)
-    project_ctx = ProjectContext(project_root)
-    process_manager = ProcessManager(max_processes=cfg.max_background_processes)
-    tool_registry = create_default_registry(project_ctx, process_manager=process_manager)
-    tool_executor = ToolExecutor(tool_registry)
-
-    # Build enhanced prompt with project structure
-    try:
-        structure = tool_registry.execute("get_project_structure", {"max_depth": 3})
-        macro = f"\n\n### PROJECT STRUCTURE:\n```\n{structure}\n```\n\nThis is the current project structure. Use `search_codebase` to locate specific code before reading files.\n"
-    except Exception:
-        macro = ""
-
-    enhanced_system = SYSTEM_PROMPT + macro
-
-    return cfg, llm_provider, tool_executor, project_ctx, enhanced_system
-
-
-def run_interactive(permissions=None, iterations=50):
-    """Run interactive chat mode (REPL)."""
-    from ayder_cli.client import ChatSession, Agent
-    from ayder_cli.core.context import SessionContext
-    from ayder_cli.commands import handle_command
-    from ayder_cli.ui import draw_box, print_running, print_assistant_message
-
-    cfg, llm_provider, tool_executor, project_ctx, enhanced_system = _build_services()
-
-    chat_session = ChatSession(cfg, enhanced_system,
-                               permissions=permissions, iterations=iterations)
-    chat_session.start()
-    agent = Agent(llm_provider, tool_executor, chat_session)
-
-    while True:
-        user_input = chat_session.get_input()
-        if user_input is None:
-            break
-        if not user_input:
-            continue
-
-        if user_input.startswith('/'):
-            session_ctx = SessionContext(
-                config=cfg, project=project_ctx,
-                messages=chat_session.messages, state=chat_session.state,
-                llm=llm_provider,
-                system_prompt=enhanced_system
-            )
-            # Track message count to detect if command added messages for agent
-            msg_count_before = len(chat_session.messages)
-            handle_command(user_input, session_ctx)
-            msg_count_after = len(chat_session.messages)
-
-            # If command added messages (e.g., /implement), process them through agent
-            if msg_count_after > msg_count_before:
-                try:
-                    print_running()
-                    # Get the last added message content
-                    last_msg = chat_session.messages[-1]
-                    if last_msg.get("role") == "user":
-                        # Remove the message we just added (agent.chat will re-add it)
-                        chat_session.messages.pop()
-                        response = agent.chat(last_msg["content"])
-                        if response is not None:
-                            print_assistant_message(response)
-                except Exception as e:
-                    draw_box(f"Error: {str(e)}", title="Error", width=80, color_code="31")
-            continue
-
-        try:
-            print_running()
-            response = agent.chat(user_input)
-            if response is not None:
-                print_assistant_message(response)
-        except Exception as e:
-            draw_box(f"Error: {str(e)}", title="Error", width=80, color_code="31")
-
-
-def run_command(prompt: str, permissions=None, iterations=50) -> int:
-    """Execute a single command and return exit code.
-
-    Args:
-        prompt: The command/prompt to execute
-        permissions: Set of granted permission categories (e.g. {"r", "w", "x"})
-        iterations: Max agentic iterations per message
-
-    Returns:
-        Exit code (0 for success, 1 for error)
-    """
-    try:
-        from ayder_cli.client import ChatSession, Agent
-
-        cfg, llm_provider, tool_executor, _, enhanced_system = _build_services()
-
-        session = ChatSession(
-            config=cfg, system_prompt=enhanced_system,
-            permissions=permissions, iterations=iterations
-        )
-        agent = Agent(llm_provider, tool_executor, session)
-
-        response = agent.chat(prompt)
-        if response:
-            print(response)
-
-        return 0
-    except Exception as e:
-        print(f"Error: {e}", file=sys.stderr)
-        return 1
-
-
-def _run_tasks_cli() -> int:
-    """List all tasks and exit."""
-    try:
-        from ayder_cli.core.context import ProjectContext
-        from ayder_cli.tasks import list_tasks
-        result = list_tasks(ProjectContext("."))
-        print(result)
-        return 0
-    except Exception as e:
-        print(f"Error: {e}", file=sys.stderr)
-        return 1
-
-
-def _run_implement_cli(task_query: str, permissions=None, iterations=50) -> int:
-    """Implement a specific task by ID or name."""
-    try:
-        from ayder_cli.client import ChatSession, Agent
-        from ayder_cli.core.context import ProjectContext
-        from ayder_cli.prompts import TASK_EXECUTION_PROMPT_TEMPLATE
-        from ayder_cli.tasks import _get_tasks_dir, _get_task_path_by_id, _extract_id, _parse_title
-
-        cfg, llm_provider, tool_executor, _, enhanced_system = _build_services()
-
-        project_ctx = ProjectContext(".")
-        tasks_dir = _get_tasks_dir(project_ctx)
-
-        # Try to find by ID first
-        try:
-            task_id = int(task_query)
-            task_path = _get_task_path_by_id(project_ctx, task_id)
-            if task_path:
-                rel_path = project_ctx.to_relative(task_path)
-                prompt = TASK_EXECUTION_PROMPT_TEMPLATE.format(task_path=rel_path)
-
-                session = ChatSession(
-                    config=cfg, system_prompt=enhanced_system,
-                    permissions=permissions, iterations=iterations
-                )
-                agent = Agent(llm_provider, tool_executor, session)
-
-                # Add the task execution prompt
-                response = agent.chat(prompt)
-                if response:
-                    print(response)
-                return 0
-        except ValueError:
-            pass
-
-        # Search by name/pattern
-        query_lower = task_query.lower()
-        for task_file in sorted(tasks_dir.glob("*.md")):
-            task_id = _extract_id(task_file.name)
-            if task_id is None:
-                continue
-            title = _parse_title(task_file)
-            if query_lower in title.lower():
-                rel_path = project_ctx.to_relative(task_file)
-                prompt = TASK_EXECUTION_PROMPT_TEMPLATE.format(task_path=rel_path)
-
-                session = ChatSession(
-                    config=cfg, system_prompt=enhanced_system,
-                    permissions=permissions, iterations=iterations
-                )
-                agent = Agent(llm_provider, tool_executor, session)
-
-                response = agent.chat(prompt)
-                if response:
-                    print(response)
-                return 0
-
-        print(f"No tasks found matching: {task_query}", file=sys.stderr)
-        return 1
-    except Exception as e:
-        print(f"Error: {e}", file=sys.stderr)
-        return 1
-
-
-def _run_implement_all_cli(permissions=None, iterations=50) -> int:
-    """Implement all pending tasks sequentially."""
-    try:
-        from ayder_cli.client import ChatSession, Agent
-        from ayder_cli.prompts import TASK_EXECUTION_ALL_PROMPT_TEMPLATE
-
-        cfg, llm_provider, tool_executor, _, enhanced_system = _build_services()
-
-        session = ChatSession(
-            config=cfg, system_prompt=enhanced_system,
-            permissions=permissions, iterations=iterations
-        )
-        agent = Agent(llm_provider, tool_executor, session)
-
-        response = agent.chat(TASK_EXECUTION_ALL_PROMPT_TEMPLATE)
-        if response:
-            print(response)
-        return 0
-    except Exception as e:
-        print(f"Error: {e}", file=sys.stderr)
-        return 1
-
-
 def main():
     """Main entry point for the CLI."""
+    from ayder_cli.cli_runner import (
+        run_interactive, run_command,
+        _run_tasks_cli, _run_implement_cli, _run_implement_all_cli
+    )
+
     parser = create_parser()
     args = parser.parse_args()
 
diff --git a/src/ayder_cli/client.py b/src/ayder_cli/client.py
index f89024a..618bd39 100644
--- a/src/ayder_cli/client.py
+++ b/src/ayder_cli/client.py
@@ -1,10 +1,20 @@
+"""
+Client module - Manages chat sessions and agents.
+
+This module provides:
+- ChatSession: Manages conversation state, history, and user input
+- Agent: High-level interface that delegates to ChatLoop for execution
+"""
+
 import asyncio
 from pathlib import Path
 from concurrent.futures import ThreadPoolExecutor
 from ayder_cli.banner import print_welcome_banner
-from ayder_cli.parser import parse_custom_tool_calls
 from ayder_cli.services.llm import LLMProvider
 from ayder_cli.services.tools.executor import ToolExecutor
+from ayder_cli.checkpoint_manager import CheckpointManager
+from ayder_cli.memory import MemoryManager
+from ayder_cli.chat_loop import ChatLoop, LoopConfig
 from prompt_toolkit import PromptSession
 from prompt_toolkit.history import FileHistory
 from prompt_toolkit.formatted_text import ANSI
@@ -48,7 +58,9 @@ class ChatSession:
     """Manage conversation state, history, and user input."""
 
     def __init__(self, config, system_prompt: str,
-                 permissions: set = None, iterations: int = 50):
+                 permissions: set = None, iterations: int = 50,
+                 checkpoint_manager: CheckpointManager = None,
+                 memory_manager: MemoryManager = None):
         """Initialize chat session.
 
         Args:
@@ -56,6 +68,8 @@ class ChatSession:
             system_prompt: Base SYSTEM_PROMPT (enhanced with project structure)
             permissions: Set of granted permission categories.
             iterations: Max agentic iterations per message.
+            checkpoint_manager: CheckpointManager for checkpoint/restore cycles.
+            memory_manager: MemoryManager for LLM-based checkpoint operations.
         """
         self.config = config
         self.system_prompt = system_prompt
@@ -66,6 +80,8 @@ class ChatSession:
             "iterations": iterations,
         }
         self.session = None
+        self.checkpoint_manager = checkpoint_manager
+        self.memory_manager = memory_manager
 
     def start(self):
         """Initialize the session, load history, print banner."""
@@ -186,79 +202,27 @@ class Agent:
         Returns:
             The assistant's text response, or None.
         """
-        self.session.add_message("user", user_input)
-
         # Get config from session
         cfg = self.session.config
-        # Use model from state if overridden, otherwise from config
         model = self.session.state.get("model", cfg.model)
-        num_ctx = cfg.num_ctx
-
-        # Get state from session
-        permissions = self.session.state.get("permissions", set())
-        max_iterations = self.session.state.get("iterations", 50)
-        verbose = self.session.state.get("verbose", False)
-
-        # Main Loop for Agentic Steps
-        for iteration in range(1, max_iterations + 1):
-            if verbose:
-                from ayder_cli.ui import draw_box
-                draw_box(
-                    f"Iteration {iteration}/{max_iterations}",
-                    title="Agent Loop", width=50, color_code="33"
-                )
-
-            schemas = [] if self.session.state.pop("no_tools", False) else self.tools.tool_registry.get_schemas()
-
-            response = self.llm.chat(
-                model=model,
-                messages=self.session.get_messages(),
-                tools=schemas,
-                options={"num_ctx": num_ctx},
-                verbose=verbose
-            )
-
-            msg = response.choices[0].message
-            content = msg.content or ""
-
-            tool_calls = msg.tool_calls
-            custom_calls = []
-            if not tool_calls:
-                custom_calls = parse_custom_tool_calls(content)
-
-                # Check for parser errors
-                for call in custom_calls:
-                    if "error" in call:
-                        self.session.add_message(
-                            "user",
-                            f"Tool parsing error: {call['error']}"
-                        )
-                        custom_calls = []
-                        break
-
-            if not tool_calls and not custom_calls:
-                # No tools used, just conversation
-                if content:
-                    self.session.add_message("assistant", content)
-                    return content
-                return None  # Empty response, no tools
-
-            # If tools were called: add the message with tool_calls
-            self.session.append_raw(msg)
-
-            # Execute tool calls
-            if tool_calls:
-                if self.tools.execute_tool_calls(tool_calls, self.session, permissions, verbose):
-                    return None  # Terminal tool hit
-            elif custom_calls:
-                if self.tools.execute_custom_calls(custom_calls, self.session, permissions, verbose):
-                    return None  # Terminal tool hit
-
-        # Max iterations reached — notify user
-        from ayder_cli.ui import draw_box
-        draw_box(
-            f"Reached maximum iterations ({max_iterations}). "
-            f"Use -I flag or max_iterations in config to increase.",
-            title="Iteration Limit", width=80, color_code="33"
+        
+        # Build loop configuration
+        loop_config = LoopConfig(
+            max_iterations=self.session.state.get("iterations", 50),
+            model=model,
+            num_ctx=cfg.num_ctx,
+            verbose=self.session.state.get("verbose", False),
+            permissions=self.session.state.get("permissions", set())
+        )
+        
+        # Create and run chat loop
+        chat_loop = ChatLoop(
+            llm_provider=self.llm,
+            tool_executor=self.tools,
+            session=self.session,
+            config=loop_config,
+            checkpoint_manager=self.session.checkpoint_manager,
+            memory_manager=self.session.memory_manager
         )
-        return None
+        
+        return chat_loop.run(user_input)
diff --git a/src/ayder_cli/commands/registry.py b/src/ayder_cli/commands/registry.py
index ddfba3d..8981a4b 100644
--- a/src/ayder_cli/commands/registry.py
+++ b/src/ayder_cli/commands/registry.py
@@ -18,6 +18,10 @@ class CommandRegistry:
     def list_commands(self) -> list[BaseCommand]:
         """List all registered commands."""
         return list(self._commands.values())
+    
+    def get_command_names(self) -> list[str]:
+        """Get all registered command names."""
+        return sorted(self._commands.keys())
 
 # Global registry instance
 _registry = CommandRegistry()
diff --git a/src/ayder_cli/commands/system.py b/src/ayder_cli/commands/system.py
index 5dbab3c..8b7c999 100644
--- a/src/ayder_cli/commands/system.py
+++ b/src/ayder_cli/commands/system.py
@@ -1,10 +1,15 @@
 from typing import Dict, Any
 from ayder_cli.ui import draw_box
 from ayder_cli.core.context import SessionContext
-from ayder_cli.prompts import SYSTEM_PROMPT, PLANNING_PROMPT_TEMPLATE
+from ayder_cli.prompts import (
+    SYSTEM_PROMPT,
+    PLANNING_PROMPT_TEMPLATE,
+    COMPACT_COMMAND_PROMPT_TEMPLATE,
+)
 from .base import BaseCommand
 from .registry import register_command, get_registry
 
+
 @register_command
 class HelpCommand(BaseCommand):
     @property
@@ -27,149 +32,26 @@ class HelpCommand(BaseCommand):
         draw_box(help_text, title="Help", width=80, color_code="33")
         return True
 
-@register_command
-class ClearCommand(BaseCommand):
-    @property
-    def name(self) -> str:
-        return "/clear"
 
-    @property
-    def description(self) -> str:
-        return "Clear conversation history and reset context"
+# NOTE: /clear, /summary, and /load commands are disabled.
+# They duplicate functionality that should be handled by MemoryManager.
+# Use /compact instead for manual checkpoint/restore cycles.
 
-    def execute(self, args: str, session: SessionContext) -> bool:
-        # Clear messages but keep system prompt if present
-        messages = session.messages
-        if messages:
-            # We assume the first message is system prompt if it exists
-            if messages[0].get("role") == "system":
-                system_msg = messages[0]
-                messages.clear()
-                messages.append(system_msg)
-            else:
-                messages.clear()
-        
-        # Add a prompt asking AI to acknowledge the reset
-        reset_prompt = (
-            "The conversation has been cleared. "
-            "Please acknowledge this reset and confirm you're ready to start fresh."
-        )
-        session.messages.append({"role": "user", "content": reset_prompt})
-        
-        draw_box("Conversation history cleared.", title="System", width=80, color_code="32")
-        return True
+# @register_command
+# class ClearCommand(BaseCommand):
+#     """DISABLED: Use automatic checkpointing or /compact instead."""
+#     pass
 
+# @register_command
+# class SummaryCommand(BaseCommand):
+#     """DISABLED: Use automatic checkpointing or /compact instead."""
+#     pass
 
-@register_command
-class SummaryCommand(BaseCommand):
-    @property
-    def name(self) -> str:
-        return "/summary"
+# @register_command
+# class LoadCommand(BaseCommand):
+#     """DISABLED: Use automatic checkpointing or /compact instead."""
+#     pass
 
-    @property
-    def description(self) -> str:
-        return "Prompt AI to summarize conversation and save to .ayder/current_memory.md"
-
-    def execute(self, args: str, session: SessionContext) -> bool:
-        # Build conversation history text
-        messages = session.messages
-        if len(messages) <= 1:
-            draw_box("No conversation to summarize.", title="System", width=80, color_code="33")
-            return True
-        
-        # Get conversation (excluding system prompts)
-        conversation = []
-        for msg in messages:
-            if msg.get("role") in ("user", "assistant"):
-                conversation.append(msg)
-        
-        if not conversation:
-            draw_box("No conversation to summarize.", title="System", width=80, color_code="33")
-            return True
-        
-        # Build conversation text
-        conversation_text = ""
-        for msg in conversation:
-            role = msg.get("role", "unknown")
-            content = msg.get("content", "")
-            conversation_text += f"[{role}] {content}\n\n"
-        
-        # Create the summarization prompt
-        summary_prompt = (
-            "Please summarize the following conversation and save it to `.ayder/current_memory.md`.\n\n"
-            "The summary should:\n"
-            "- Capture key decisions, context, and progress\n"
-            "- Be concise but comprehensive\n"
-            "- Help future me understand what we've done so far\n\n"
-            f"Conversation:\n{conversation_text}\n\n"
-            "Use the write_file tool to save the summary to `.ayder/current_memory.md`."
-        )
-        
-        # Add the prompt as a user message for the agent to process
-        session.messages.append({"role": "user", "content": summary_prompt})
-        
-        draw_box(
-            "Summary request submitted. The AI will summarize and save to .ayder/current_memory.md",
-            title="Summary",
-            width=80,
-            color_code="36"
-        )
-        return True
-
-
-@register_command
-class LoadCommand(BaseCommand):
-    @property
-    def name(self) -> str:
-        return "/load"
-
-    @property
-    def description(self) -> str:
-        return "Prompt AI to load memory from .ayder/current_memory.md"
-
-    def execute(self, args: str, session: SessionContext) -> bool:
-        memory_file = session.project.root / ".ayder" / "current_memory.md"
-        
-        if not memory_file.exists():
-            draw_box(
-                f"Memory file not found: {memory_file}\nRun /summary first to create it.",
-                title="Load",
-                width=80,
-                color_code="33"
-            )
-            return True
-        
-        try:
-            content = memory_file.read_text(encoding="utf-8")
-            
-            # Create a prompt for the AI to acknowledge the loaded memory
-            load_prompt = (
-                "I've loaded the previous conversation memory from `.ayder/current_memory.md`. "
-                "Please acknowledge this context and continue from where we left off.\n\n"
-                "[Memory from previous conversation]:\n"
-                f"{content}"
-            )
-            
-            # Add as a user message for the agent to process
-            session.messages.append({"role": "user", "content": load_prompt})
-            
-            draw_box(
-                f"Memory loaded from: {memory_file}\n"
-                "The AI will acknowledge this context.",
-                title="Load",
-                width=80,
-                color_code="32"
-            )
-            
-        except Exception as e:
-            draw_box(
-                f"Error loading memory: {str(e)}",
-                title="Error",
-                width=80,
-                color_code="31"
-            )
-        
-        return True
 
 @register_command
 class VerboseCommand(BaseCommand):
@@ -188,6 +70,7 @@ class VerboseCommand(BaseCommand):
         draw_box(f"Verbose mode: {status}", title="System", width=80, color_code="34")
         return True
 
+
 @register_command
 class CompactCommand(BaseCommand):
     @property
@@ -226,15 +109,9 @@ class CompactCommand(BaseCommand):
         if system_msg:
             messages.append(system_msg)
         
-        # Combined prompt: summarize, save, and acknowledge
-        compact_prompt = (
-            "I am compacting our conversation. Please do the following:\n\n"
-            "1. SUMMARIZE this conversation:\n"
-            f"{conversation_text}\n"
-            "2. SAVE the summary to `.ayder/current_memory.md` using write_file\n"
-            "3. CONFIRM the conversation has been reset\n"
-            "4. ACKNOWLEDGE the saved context so we can continue\n\n"
-            "Provide a brief summary, save it, confirm reset, and acknowledge the context."
+        # Create compact prompt using the template
+        compact_prompt = COMPACT_COMMAND_PROMPT_TEMPLATE.format(
+            conversation_text=conversation_text
         )
         
         messages.append({"role": "user", "content": compact_prompt})
diff --git a/src/ayder_cli/memory.py b/src/ayder_cli/memory.py
index 853fb32..8cc1929 100644
--- a/src/ayder_cli/memory.py
+++ b/src/ayder_cli/memory.py
@@ -1,7 +1,10 @@
 """
-Cross-session memory storage for ayder-cli.
+Cross-session memory storage and LLM-based checkpoint operations for ayder-cli.
+
+This module provides:
+1. Persistent memory storage (JSON Lines in .ayder/memory/memories.jsonl)
+2. LLM-based checkpoint/restore operations for long-running sessions
 
-Stores memories as JSON Lines (.jsonl) in .ayder/memory/memories.jsonl.
 Imports from core/result.py (NOT from tools/) to avoid circular imports.
 """
 
@@ -9,9 +12,17 @@ import json
 import uuid
 from datetime import datetime
 from pathlib import Path
+from typing import Optional, Callable
 
 from ayder_cli.core.context import ProjectContext
 from ayder_cli.core.result import ToolSuccess, ToolError
+from ayder_cli.checkpoint_manager import CHECKPOINT_FILE_NAME
+from ayder_cli.prompts import (
+    MEMORY_CHECKPOINT_PROMPT_TEMPLATE,
+    MEMORY_RESTORE_PROMPT_TEMPLATE,
+    MEMORY_QUICK_RESTORE_MESSAGE_TEMPLATE,
+    MEMORY_NO_MEMORY_MESSAGE,
+)
 
 
 def _get_memory_dir(project_ctx: ProjectContext) -> Path:
@@ -109,3 +120,220 @@ def load_memory(project_ctx: ProjectContext, category: str = None, query: str =
 
     except Exception as e:
         return ToolError(f"Error loading memories: {str(e)}", "execution")
+
+
+class MemoryManager:
+    """Manages LLM-based checkpoint/restore operations for long-running agent sessions.
+    
+    This class handles all LLM interactions related to memory operations, including:
+    - Creating checkpoints by asking the LLM to summarize progress
+    - Restoring context from saved checkpoints
+    - Building prompts for checkpoint and restore operations
+    
+    File I/O for checkpoints is delegated to CheckpointManager.
+    """
+    
+    def __init__(
+        self,
+        project_ctx: ProjectContext,
+        llm_provider=None,
+        tool_executor=None,
+        checkpoint_manager=None
+    ):
+        """Initialize MemoryManager.
+        
+        Args:
+            project_ctx: Project context for path resolution
+            llm_provider: LLM provider for making checkpoint calls
+            tool_executor: Tool executor for executing save operations
+            checkpoint_manager: CheckpointManager for file I/O operations
+        """
+        self.project_ctx = project_ctx
+        self.llm = llm_provider
+        self.tool_executor = tool_executor
+        self.cm = checkpoint_manager
+        self._checkpoint_dir = project_ctx.root / ".ayder" / "memory"
+        self._checkpoint_file = self._checkpoint_dir / CHECKPOINT_FILE_NAME
+        self._cycle_count = 0
+    
+    def _ensure_checkpoint_dir(self) -> None:
+        """Ensure the checkpoint directory exists."""
+        self._checkpoint_dir.mkdir(parents=True, exist_ok=True)
+    
+    def _read_checkpoint(self) -> Optional[str]:
+        """Read the current checkpoint content if it exists.
+        
+        Returns:
+            Checkpoint content as string, or None if no checkpoint exists
+        """
+        if not self._checkpoint_file.exists():
+            return None
+        try:
+            return self._checkpoint_file.read_text(encoding="utf-8")
+        except Exception:
+            return None
+    
+    def build_checkpoint_prompt(self, conversation_summary: str) -> str:
+        """Build the prompt asking LLM to create a checkpoint.
+        
+        Args:
+            conversation_summary: Summary of the current conversation/state
+            
+        Returns:
+            Prompt string for the LLM
+        """
+        return MEMORY_CHECKPOINT_PROMPT_TEMPLATE.format(
+            conversation_summary=conversation_summary,
+            memory_file_name=CHECKPOINT_FILE_NAME
+        )
+    
+    def build_restore_prompt(self, checkpoint_content: Optional[str] = None) -> str:
+        """Build the prompt for restoring context from checkpoint.
+        
+        Args:
+            checkpoint_content: Optional pre-loaded checkpoint content
+            
+        Returns:
+            Prompt string for restoring context
+        """
+        if checkpoint_content is None:
+            checkpoint_content = self._read_checkpoint() or "No previous checkpoint found."
+        
+        return MEMORY_RESTORE_PROMPT_TEMPLATE.format(
+            memory_file_name=CHECKPOINT_FILE_NAME,
+            memory_content=checkpoint_content
+        )
+    
+    def build_quick_restore_message(self) -> str:
+        """Build a quick restore message for after a checkpoint cycle.
+        
+        Returns:
+            User message content for restoring context
+        """
+        checkpoint_content = self._read_checkpoint()
+        if not checkpoint_content:
+            return MEMORY_NO_MEMORY_MESSAGE
+        
+        return MEMORY_QUICK_RESTORE_MESSAGE_TEMPLATE.format(
+            memory_content=checkpoint_content
+        )
+    
+    def create_checkpoint(
+        self,
+        session,
+        model: str,
+        num_ctx: int,
+        permissions: set,
+        verbose: bool
+    ) -> bool:
+        """Create a memory checkpoint by asking LLM to write a summary.
+        
+        This method orchestrates the LLM interaction to create a checkpoint:
+        1. Builds a conversation summary
+        2. Asks LLM to create a checkpoint via prompt
+        3. Executes any tool calls from LLM response
+        4. Resets the conversation
+        5. Loads back the memory as a user message
+        
+        Args:
+            session: Chat session for message management
+            model: Model name
+            num_ctx: Context window size
+            permissions: Granted permission categories
+            verbose: Whether to show verbose output
+            
+        Returns:
+            True if checkpoint was created successfully, False otherwise
+        """
+        if not self.llm or not self.tool_executor:
+            return False
+        
+        # Build a summary of the conversation so far
+        conversation_summary = self._build_conversation_summary(session)
+        
+        # Step 1: Ask LLM to write memory checkpoint
+        checkpoint_prompt = self.build_checkpoint_prompt(conversation_summary)
+        session.add_message("user", checkpoint_prompt)
+        
+        # Get schemas for tools (we need write_file tool)
+        schemas = self.tool_executor.tool_registry.get_schemas()
+        
+        response = self.llm.chat(
+            model=model,
+            messages=session.get_messages(),
+            tools=schemas,
+            options={"num_ctx": num_ctx},
+            verbose=verbose
+        )
+        
+        msg = response.choices[0].message
+        content = msg.content or ""
+        tool_calls = msg.tool_calls
+        
+        # If LLM made tool calls to save memory, execute them
+        if tool_calls:
+            session.append_raw(msg)
+            self.tool_executor.execute_tool_calls(tool_calls, session, permissions, verbose)
+        elif content:
+            # LLM responded with text, maybe it already saved or we need to retry
+            session.add_message("assistant", content)
+        
+        # Step 2: Reset the conversation (keep only system message)
+        session.clear_messages(keep_system=True)
+        
+        # Step 3: Load back the memory as a user message
+        restore_msg = self.build_quick_restore_message()
+        session.add_message("user", restore_msg)
+        
+        self._cycle_count += 1
+        
+        return True
+    
+    def restore_from_checkpoint(self, session) -> None:
+        """Restore session from saved checkpoint.
+        
+        Args:
+            session: Chat session to restore
+        """
+        session.clear_messages(keep_system=True)
+        restore_msg = self.build_quick_restore_message()
+        session.add_message("user", restore_msg)
+    
+    def _build_conversation_summary(self, session) -> str:
+        """Build a summary of recent conversation.
+        
+        Args:
+            session: Chat session with messages
+            
+        Returns:
+            String summary of last 10 messages
+        """
+        summary = ""
+        for msg in session.get_messages()[-10:]:  # Last 10 messages
+            role = msg.get("role", "unknown")
+            content = msg.get("content", "")[:200]  # Truncate long content
+            if content:
+                summary += f"[{role}] {content[:100]}...\n"
+        return summary
+
+
+def create_memory_manager(
+    project_root: str = ".",
+    llm_provider=None,
+    tool_executor=None,
+    checkpoint_manager=None
+) -> MemoryManager:
+    """Factory function to create a MemoryManager instance.
+    
+    Args:
+        project_root: Project root directory path
+        llm_provider: LLM provider for making checkpoint calls
+        tool_executor: Tool executor for executing save operations
+        checkpoint_manager: CheckpointManager for file I/O operations
+        
+    Returns:
+        Configured MemoryManager instance
+    """
+    from ayder_cli.core.context import ProjectContext
+    project_ctx = ProjectContext(project_root)
+    return MemoryManager(project_ctx, llm_provider, tool_executor, checkpoint_manager)
diff --git a/src/ayder_cli/prompts.py b/src/ayder_cli/prompts.py
index 5ff5b02..80db7a2 100644
--- a/src/ayder_cli/prompts.py
+++ b/src/ayder_cli/prompts.py
@@ -1,4 +1,16 @@
-"""System prompts and prompt templates for ayder-cli."""
+"""System prompts and prompt templates for ayder-cli.
+
+Each prompt template is labeled with a comment indicating which module/function
+is responsible for using it, along with the REASON for prompting the LLM.
+"""
+
+# =============================================================================
+# CORE SYSTEM PROMPT
+# =============================================================================
+# Used by: cli_runner.py::_build_services()
+# REASON: Define the AI's role as an autonomous software engineer, establish
+# operational principles, reasoning workflow, tool protocol, and available
+# capabilities. This sets the foundation for all interactions.
 
 SYSTEM_PROMPT = """You are the expert Autonomous Software Engineer. You do not just write code; you solve problems by interacting with the environment.
 
@@ -16,7 +28,7 @@ SYSTEM_PROMPT = """You are the expert Autonomous Software Engineer. You do not j
 - ALWAYS: Keep responses concise. Only output your thought process and the tool call.
 - NEVER: assume a tool worked. Check the exit code or file contents after every action.
 - if a tool not worked as expected inform user, give debug information.
-- Response with "Great" after each successful task
+- Response with "Perfect" after each successful task
 
 ### FORMAT:
 Use the following structure:
@@ -58,6 +70,33 @@ You can perform these actions:
 """
 
 
+# =============================================================================
+# PROJECT STRUCTURE MACRO
+# =============================================================================
+# Used by: cli_runner.py::_build_services()
+# REASON: Provide the LLM with an overview of the project structure at startup
+# so it knows what files and directories exist. This helps the LLM understand
+# the codebase layout before starting work and guides it to use search_codebase
+# to locate specific code rather than blindly exploring.
+
+PROJECT_STRUCTURE_MACRO_TEMPLATE = """
+
+### PROJECT STRUCTURE:
+```
+{project_structure}
+```
+
+This is the current project structure. Use `search_codebase` to locate specific code before reading files.
+"""
+
+
+# =============================================================================
+# TASK PLANNING PROMPTS
+# =============================================================================
+# Used by: commands/system.py::PlanCommand.execute()
+# REASON: Transform a high-level user request into actionable, discrete tasks
+# with clear acceptance criteria. Forces the LLM to plan before executing.
+
 PLANNING_PROMPT_TEMPLATE = """You are a development task planner. Analyze the user's request thoroughly and split into logical, sequential multiple tasks where each development  will only effect in 2-3 files each. Use write_file tool to generate files under .ayder/tasks folder each TASK-<task slug>.md in full PRD format with acceptance criteria.
 **ALWAYS** Wait for user to review the tasks.
 **NEVER** Start task implementation before user approval. STOP loop after succesful task generation.
@@ -73,9 +112,20 @@ Check existings tasks and increment biggest <NNN> for new tasks.
 User Request: {task_description}"""
 
 
+# =============================================================================
+# TASK EXECUTION PROMPTS
+# =============================================================================
+# Used by: cli_runner.py::TaskRunner._execute_task()
+# REASON: Instruct the LLM to implement a specific task file and mark it complete.
+# Keeps the LLM focused on a single task at a time.
+
 TASK_EXECUTION_PROMPT_TEMPLATE = """analyze file {task_path} and implement every detail according to the description and acceptance criteria. After successful implementation, mark the task as complete by changing '- **Status:** pending' to '- **Status:** done' in {task_path}. Stop iteration after changing the status, wait for user review"""
 
 
+# Used by: cli_runner.py::TaskRunner.implement_all()
+# REASON: Instruct the LLM to process all pending tasks sequentially without
+# stopping between tasks. Enables batch task completion.
+
 TASK_EXECUTION_ALL_PROMPT_TEMPLATE = """Find all tasks with status 'pending' or 'todo' in .ayder/tasks/ folder. Implement each undone task in sequential order according to their task numbers. For each task:
 1. Read the task file
 2. Implement every detail according to the description and acceptance criteria
@@ -84,3 +134,115 @@ TASK_EXECUTION_ALL_PROMPT_TEMPLATE = """Find all tasks with status 'pending' or
 5. Repeat until all tasks are complete
 
 If you encounter errors, fix them and continue. Only stop when all tasks are marked as done."""
+
+
+# =============================================================================
+# MEMORY & CONVERSATION MANAGEMENT PROMPTS (commands/system.py)
+# =============================================================================
+# Used by: commands/system.py::ClearCommand.execute()
+# REASON: After clearing conversation history, confirm the LLM understands
+# the context is fresh and ready for new work.
+
+CLEAR_COMMAND_RESET_PROMPT = """The conversation has been cleared. Please acknowledge this reset and confirm you're ready to start fresh."""
+
+
+# Used by: commands/system.py::SummaryCommand.execute()
+# REASON: Extract key decisions and context from a long conversation and
+# persist it to a memory file for future reference or session restoration.
+
+SUMMARY_COMMAND_PROMPT_TEMPLATE = """Please summarize the following conversation and save it to `.ayder/current_memory.md`.
+
+The summary should:
+- Capture key decisions, context, and progress
+- Be concise but comprehensive
+- Help future me understand what we've done so far
+
+Conversation:
+{conversation_text}
+
+Use the write_file tool to save the summary to `.ayder/current_memory.md`."""
+
+
+# Used by: commands/system.py::LoadCommand.execute()
+# REASON: Restore context from a previously saved memory file so the LLM
+# can continue work from where it left off in a previous session.
+
+LOAD_MEMORY_COMMAND_PROMPT_TEMPLATE = """I've loaded the previous conversation memory from `.ayder/current_memory.md`. 
+Please acknowledge this context and continue from where we left off.
+
+[Memory from previous conversation]:
+{memory_content}"""
+
+
+# Used by: commands/system.py::CompactCommand.execute()
+# REASON: Combine summary, save, clear, and reload into a single operation
+# to prevent context window overflow while maintaining continuity.
+
+COMPACT_COMMAND_PROMPT_TEMPLATE = """I am compacting our conversation. Please do the following:
+
+1. SUMMARIZE this conversation:
+{conversation_text}
+2. SAVE the summary to `.ayder/current_memory.md` using write_file
+3. CONFIRM the conversation has been reset
+4. ACKNOWLEDGE the saved context so we can continue
+
+Provide a brief summary, save it, confirm reset, and acknowledge the context."""
+
+
+# =============================================================================
+# MEMORY CHECKPOINT PROMPTS (checkpoint_manager.py)
+# =============================================================================
+# Used by: memory.py::MemoryManager.build_checkpoint_prompt()
+# REASON: When iteration limit is reached, force the LLM to save progress
+# before automatic context reset. Prevents loss of work during long tasks.
+
+MEMORY_CHECKPOINT_PROMPT_TEMPLATE = """You are approaching the iteration limit. To prevent context loss and continue efficiently, please create a memory checkpoint:
+
+1. SUMMARIZE the current task progress, key decisions, and important context from this conversation:
+{conversation_summary}
+
+2. SAVE this summary to the memory file at `.ayder/memory/{memory_file_name}` using the write_file tool.
+
+The summary should include:
+- What task is being worked on
+- What has been completed so far
+- What is the next step
+- Any important context, file paths, or decisions made
+- Any errors encountered and how they were/will be resolved
+
+Be concise but comprehensive - this memory will be used to continue the task after a context reset."""
+
+
+# Used by: memory.py::MemoryManager.build_restore_prompt()
+# REASON: After automatic context reset at iteration limit, instruct the LLM
+# to read the saved memory and continue the task without losing progress.
+
+MEMORY_RESTORE_PROMPT_TEMPLATE = """I've reset the conversation context to prevent token overflow. Please read the memory file at `.ayder/memory/{memory_file_name}` and continue from where we left off.
+
+Based on the saved memory:
+```
+{memory_content}
+```
+
+Acknowledge the context restoration and continue working on the task. Maintain the same approach and context as before the reset."""
+
+
+# Used by: memory.py::MemoryManager.build_quick_restore_message()
+# REASON: User-facing message that includes the saved memory content directly
+# in the prompt for immediate context restoration after checkpoint reset.
+
+MEMORY_QUICK_RESTORE_MESSAGE_TEMPLATE = """[SYSTEM: Context reset completed. Continuing from saved memory.]
+
+Previous context from memory checkpoint:
+---
+{memory_content}
+---
+
+Please acknowledge and continue the task from where we left off."""
+
+
+# Used by: memory.py::MemoryManager.build_quick_restore_message()
+# REASON: Fallback when no memory was saved before the checkpoint reset.
+# Informs the user that the context was reset but no previous state exists.
+
+MEMORY_NO_MEMORY_MESSAGE = """Continuing task after context reset. No previous memory was saved."""
diff --git a/src/ayder_cli/tui.py b/src/ayder_cli/tui.py
index 89694c7..fbc3c37 100644
--- a/src/ayder_cli/tui.py
+++ b/src/ayder_cli/tui.py
@@ -1,30 +1,39 @@
 """
-Textual TUI (Terminal User Interface) for ayder-cli.
+CLI-style TUI (Terminal User Interface) for ayder-cli.
 
-Provides an interactive dashboard with:
-- Chat history view
-- Input bar
-- Context panel with file tree and model info
-- Status bar
+Provides a clean, terminal-like interface:
+- Simple text output with prefixes (> for user, < for assistant)
+- Minimal borders and chrome
+- Slash command auto-completion
+- Status bar with context info
 """
 
 from textual.app import App, ComposeResult
 from textual.containers import Container, Horizontal, VerticalScroll, Vertical
-from textual.widgets import Header, Footer, Static, Input, Button, Tree, Label
+from textual.widgets import Static, Input, Button, Label
 from textual.reactive import reactive
 from textual.message import Message
 from textual.worker import Worker, get_current_worker
 from textual.screen import ModalScreen
-from rich.markdown import Markdown
+from textual.suggester import SuggestFromList
+from textual.timer import Timer
+from textual import on
 from rich.text import Text
-from rich.panel import Panel
+from rich.markdown import Markdown
+from rich.spinner import Spinner
 from enum import Enum
+from pathlib import Path
+import asyncio
+import json
 
 from ayder_cli.tools.registry import ToolRegistry, create_default_registry
 from ayder_cli.core.context import ProjectContext
 from ayder_cli.client import call_llm_async
 from ayder_cli.core.config import load_config
 from ayder_cli.services.llm import OpenAIProvider
+from ayder_cli.commands.registry import get_registry
+from ayder_cli.banner import create_tui_banner
+from ayder_cli.tui_theme_manager import get_theme_css
 
 
 class MessageType(Enum):
@@ -36,57 +45,13 @@ class MessageType(Enum):
     SYSTEM = "system"
 
 
-class ConfirmActionScreen(ModalScreen[bool]):
-    """
-    Modal screen for confirming actions with optional diff preview.
-    
-    Returns:
-        True if approved, False if rejected
+
+class CLIConfirmScreen(ModalScreen[bool]):
     """
-    
-    DEFAULT_CSS = """
-    ConfirmActionScreen {
-        align: center middle;
-    }
-    
-    ConfirmActionScreen > Vertical {
-        width: 80;
-        height: auto;
-        max-height: 80%;
-        border: thick $primary;
-        background: $surface;
-        padding: 1 2;
-    }
-    
-    ConfirmActionScreen .title {
-        text-style: bold;
-        text-align: center;
-        color: $primary;
-        margin-bottom: 1;
-    }
-    
-    ConfirmActionScreen .description {
-        margin-bottom: 1;
-    }
-    
-    ConfirmActionScreen .diff-container {
-        height: 20;
-        border: solid $primary-darken-2;
-        margin: 1 0;
-        padding: 1;
-        overflow: auto scroll;
-    }
-    
-    ConfirmActionScreen .buttons {
-        height: auto;
-        align: center middle;
-    }
-    
-    ConfirmActionScreen Button {
-        margin: 0 1;
-    }
+    CLI-style confirmation screen.
+    Appears as an overlay at the bottom, not a centered popup.
     """
-    
+
     def __init__(
         self,
         title: str,
@@ -95,610 +60,1237 @@ class ConfirmActionScreen(ModalScreen[bool]):
         action_name: str = "Confirm"
     ):
         super().__init__()
-        self.title = title
+        self.title_text = title
         self.description = description
         self.diff_content = diff_content
         self.action_name = action_name
-    
+
     def compose(self) -> ComposeResult:
         """Compose the modal."""
         with Vertical():
-            yield Label(self.title, classes="title")
-            yield Label(self.description, classes="description")
-            
-            # Show diff if provided
+            yield Label(f"? {self.title_text}", classes="prompt")
+            yield Label(self.description)
+
             if self.diff_content:
-                diff_widget = Static(
-                    self._render_diff(),
-                    classes="diff-container"
-                )
-                yield diff_widget
-            
+                diff_text = self._render_diff()
+                yield Static(diff_text, classes="diff-container")
+
             with Horizontal(classes="buttons"):
-                yield Button("Cancel", variant="error", id="cancel-btn")
-                yield Button(self.action_name, variant="success", id="confirm-btn")
-    
-    def _render_diff(self) -> Panel:
+                yield Button("[Y]es", variant="success", id="confirm-btn")
+                yield Button("[N]o", variant="error", id="cancel-btn")
+
+    def _render_diff(self) -> Text:
         """Render diff content with syntax highlighting."""
-        # Colorize diff lines
         lines = self.diff_content.split('\n')
-        colorized = []
-        
+        result = Text()
+
         for line in lines:
             if line.startswith('@@'):
-                colorized.append(f"[cyan]{line}[/cyan]")
+                result.append(line + "\n", style="cyan")
             elif line.startswith('-') and not line.startswith('---'):
-                colorized.append(f"[red]{line}[/red]")
+                result.append(line + "\n", style="red")
             elif line.startswith('+') and not line.startswith('+++'):
-                colorized.append(f"[green]{line}[/green]")
+                result.append(line + "\n", style="green")
             else:
-                colorized.append(line)
-        
-        content = '\n'.join(colorized)
-        return Panel(content, title="Preview")
-    
+                result.append(line + "\n", style="dim")
+
+        return result
+
     def on_button_pressed(self, event: Button.Pressed) -> None:
         """Handle button presses."""
         if event.button.id == "confirm-btn":
             self.dismiss(True)
         else:
             self.dismiss(False)
-    
+
     def on_key(self, event) -> None:
         """Handle keyboard shortcuts."""
-        if event.key == "escape":
+        key = event.key.lower()
+        if key in ("escape", "n", "q"):
             self.dismiss(False)
-        elif event.key == "enter":
+        elif key in ("enter", "y"):
             self.dismiss(True)
 
 
-class SafeModeBlockScreen(ModalScreen):
+class CLISafeModeScreen(ModalScreen):
     """
-    Modal screen shown when a tool is blocked in safe mode.
+    CLI-style safe mode block screen.
     """
-    
-    DEFAULT_CSS = """
-    SafeModeBlockScreen {
-        align: center middle;
-    }
-    
-    SafeModeBlockScreen > Vertical {
-        width: 60;
-        height: auto;
-        border: thick $error;
-        background: $surface;
-        padding: 1 2;
-    }
-    
-    SafeModeBlockScreen .title {
-        text-style: bold;
-        text-align: center;
-        color: $error;
-        margin-bottom: 1;
-    }
-    """
-    
+
     def __init__(self, tool_name: str):
         super().__init__()
         self.tool_name = tool_name
-    
+
     def compose(self) -> ComposeResult:
         with Vertical():
-            yield Label("⛔ Safe Mode", classes="title")
-            yield Label(f"Tool '{self.tool_name}' is blocked in safe mode.")
+            yield Label(f"⛔ Safe Mode: '{self.tool_name}' blocked", classes="title")
             yield Label("Restart without --safe to enable this tool.")
-            yield Button("OK", variant="primary", id="ok-btn")
-    
-    def on_button_pressed(self, event: Button.Pressed) -> None:
+            yield Label("Press any key to continue...", classes="dim")
+
+    def on_key(self, event) -> None:
         self.dismiss()
 
 
-class ChatMessage:
-    """Represents a single chat message."""
-    
-    def __init__(self, content: str, msg_type: MessageType, metadata: dict = None):
-        self.content = content
-        self.type = msg_type
-        self.metadata = metadata or {}
-    
-    def __rich__(self):
-        """Render message as Rich content."""
-        if self.type == MessageType.USER:
-            return Panel(
-                self.content,
-                title="You",
-                border_style="cyan",
-                padding=(1, 2)
-            )
-        elif self.type == MessageType.ASSISTANT:
-            # Render markdown for assistant messages
-            md = Markdown(self.content)
-            return Panel(
-                md,
-                title="Assistant",
-                border_style="green",
-                padding=(1, 2)
-            )
-        elif self.type == MessageType.TOOL_CALL:
-            tool_name = self.metadata.get("tool_name", "unknown")
-            return Panel(
-                f"[yellow]{tool_name}[/yellow]({self.content})",
-                title="Tool Call",
-                border_style="yellow",
-                padding=(1, 2)
-            )
-        elif self.type == MessageType.TOOL_RESULT:
-            # Truncate long results
-            content = self.content
-            if len(content) > 500:
-                content = content[:500] + "..."
-            return Panel(
-                f"[green]✓[/green] {content}",
-                title="Result",
-                border_style="bright_black",
-                padding=(1, 2)
-            )
-        else:
-            return Panel(
-                self.content,
-                border_style="white",
-                padding=(1, 2)
-            )
+class CLISelectScreen(ModalScreen[str | None]):
+    """
+    CLI-style selection screen with up/down navigation.
+    Appears as an overlay at the bottom with a selectable list.
+    Returns the selected value or None if cancelled.
+    """
+
+    def __init__(
+        self,
+        title: str,
+        items: list[tuple[str, str]],
+        current: str = "",
+        description: str = ""
+    ):
+        """
+        Initialize the select screen.
+
+        Args:
+            title: The title/prompt to display
+            items: List of (value, display_text) tuples
+            current: Currently selected value (to highlight)
+            description: Optional description text
+        """
+        super().__init__()
+        self.title_text = title
+        self.items = items
+        self.current_value = current
+        self.description = description
+        self.selected_index = 0
+
+        # Find current index
+        for i, (value, _) in enumerate(items):
+            if value == current:
+                self.selected_index = i
+                break
+
+    def compose(self) -> ComposeResult:
+        """Compose the selection modal."""
+        with Vertical():
+            yield Label(f"? {self.title_text}", classes="prompt")
+
+            if self.description:
+                yield Label(self.description, classes="description")
+
+            # Build the list display
+            list_content = self._render_list()
+            yield Static(list_content, id="select-list", classes="select-list")
+
+            yield Label("↑↓ to navigate, Enter to select, Esc to cancel", classes="hint")
+
+    def _render_list(self) -> Text:
+        """Render the selectable list with current highlight."""
+        result = Text()
+
+        for i, (value, display) in enumerate(self.items):
+            is_selected = i == self.selected_index
+            is_current = value == self.current_value
+
+            if is_selected:
+                # Highlighted row
+                result.append(" → ", style="bold cyan")
+                if is_current:
+                    result.append(f"{display}", style="bold green")
+                    result.append(" (current)", style="dim green")
+                else:
+                    result.append(f"{display}", style="bold white")
+            else:
+                # Normal row
+                result.append("   ", style="dim")
+                if is_current:
+                    result.append(f"{display}", style="green")
+                    result.append(" (current)", style="dim")
+                else:
+                    result.append(f"{display}", style="white")
+
+            result.append("\n")
+
+        return result
+
+    def _update_display(self) -> None:
+        """Update the list display after navigation."""
+        list_widget = self.query_one("#select-list", Static)
+        list_widget.update(self._render_list())
+
+    def on_key(self, event) -> None:
+        """Handle keyboard navigation."""
+        key = event.key.lower()
+
+        if key in ("up", "k"):
+            event.stop()
+            self.selected_index = max(0, self.selected_index - 1)
+            self._update_display()
+        elif key in ("down", "j"):
+            event.stop()
+            self.selected_index = min(len(self.items) - 1, self.selected_index + 1)
+            self._update_display()
+        elif key in ("enter", "return"):
+            event.stop()
+            if self.items:
+                self.dismiss(self.items[self.selected_index][0])
+            else:
+                self.dismiss(None)
+        elif key in ("escape", "q"):
+            event.stop()
+            self.dismiss(None)
 
 
 class ChatView(VerticalScroll):
     """
-    Scrollable widget for displaying chat messages.
-    
-    Supports:
-    - User messages (cyan panels)
-    - Assistant messages (green panels with markdown)
-    - Tool calls (yellow panels)
-    - Tool results (dim panels)
+    CLI-style chat display.
+    Simple text output with prefixes instead of panels.
     """
-    
-    DEFAULT_CSS = """
-    ChatView {
-        height: 100%;
-        border: solid $primary;
-        padding: 1;
-    }
-    """
-    
+
     messages: reactive[list] = reactive(list)
-    
+
     def __init__(self, **kwargs):
         super().__init__(**kwargs)
         self._message_widgets: list[Static] = []
-    
+        self._thinking_widget: Static | None = None
+        self._thinking_spinner: Spinner | None = None
+
+    def _create_text(self, content: str, msg_type: MessageType, metadata: dict = None) -> Text:
+        """Create styled text for a message."""
+        if msg_type == MessageType.USER:
+            text = Text()
+            text.append("> ", style="bold cyan")
+            text.append(content, style="cyan")
+            return text
+
+        elif msg_type == MessageType.ASSISTANT:
+            return None
+
+        elif msg_type == MessageType.TOOL_CALL:
+            tool_name = metadata.get("tool_name", "unknown") if metadata else "unknown"
+            text = Text()
+            text.append("  → ", style="dim")
+            text.append(f"{tool_name}", style="bold yellow")
+            if content:
+                text.append(f"({content})", style="yellow")
+            return text
+
+        elif msg_type == MessageType.TOOL_RESULT:
+            text = Text()
+            text.append("  ✓ ", style="bold green")
+            result = content
+            if len(result) > 200:
+                result = result[:200] + "..."
+            text.append(result, style="dim")
+            return text
+
+        else:
+            text = Text()
+            text.append("# ", style="dim")
+            text.append(content, style="dim italic")
+            return text
+
     def add_message(self, content: str, msg_type: MessageType, metadata: dict = None) -> None:
-        """
-        Add a message to the chat view.
-        
-        Args:
-            content: Message content
-            msg_type: Type of message
-            metadata: Additional metadata (e.g., tool_name)
-        """
-        message = ChatMessage(content, msg_type, metadata)
-        self.messages.append(message)
-        
-        # Create and mount the message widget
-        msg_widget = Static(message, classes=f"message {msg_type.value}")
-        self._message_widgets.append(msg_widget)
-        self.mount(msg_widget)
-        
-        # Scroll to bottom
+        """Add a message to the chat view."""
+        self.messages.append({"content": content, "type": msg_type, "metadata": metadata})
+
+        if msg_type == MessageType.ASSISTANT:
+            content = content.strip()
+
+            prefix = Text()
+            prefix.append("< ", style="bold green")
+            msg_widget = Static(prefix, classes=f"message {msg_type.value}")
+            self._message_widgets.append(msg_widget)
+            self.mount(msg_widget)
+
+            content_widget = Static(
+                Markdown(content), classes=f"message {msg_type.value}-content"
+            )
+
+            self._message_widgets.append(content_widget)
+            self.mount(content_widget)
+        else:
+            text = self._create_text(content, msg_type, metadata)
+            if text:
+                msg_widget = Static(text, classes=f"message {msg_type.value}")
+                self._message_widgets.append(msg_widget)
+                self.mount(msg_widget)
+
         self.scroll_end(animate=False)
-    
+
     def add_user_message(self, content: str) -> None:
         """Add a user message."""
         self.add_message(content, MessageType.USER)
-    
+
     def add_assistant_message(self, content: str) -> None:
-        """Add an assistant message (rendered as markdown)."""
+        """Add an assistant message."""
         self.add_message(content, MessageType.ASSISTANT)
-    
+
     def add_tool_call(self, tool_name: str, arguments: str) -> None:
         """Add a tool call message."""
         self.add_message(arguments, MessageType.TOOL_CALL, {"tool_name": tool_name})
-    
+
     def add_tool_result(self, result: str) -> None:
         """Add a tool result message."""
         self.add_message(result, MessageType.TOOL_RESULT)
-    
+
     def add_system_message(self, content: str) -> None:
         """Add a system message."""
         self.add_message(content, MessageType.SYSTEM)
-    
+
+    def show_thinking(self) -> None:
+        """Show a thinking/loading indicator with a Rich spinner."""
+        if self._thinking_widget is None:
+            self._thinking_spinner = Spinner(
+                "dots2", text="Thinking...", style="bold yellow"
+            )
+            self._thinking_widget = Static(
+                self._thinking_spinner, classes="thinking-message"
+            )
+            self._message_widgets.append(self._thinking_widget)
+            self.mount(self._thinking_widget)
+            self.scroll_end(animate=False)
+
+    def _update_thinking(self) -> None:
+        """Re-render the spinner (it auto-advances based on time)."""
+        if self._thinking_widget is not None and self._thinking_spinner is not None:
+            self._thinking_widget.update(self._thinking_spinner)
+
+    def hide_thinking(self) -> None:
+        """Hide the thinking/loading indicator."""
+        if self._thinking_widget is not None:
+            self._thinking_widget.remove()
+            if self._thinking_widget in self._message_widgets:
+                self._message_widgets.remove(self._thinking_widget)
+            self._thinking_widget = None
+            self._thinking_spinner = None
+
     def clear_messages(self) -> None:
         """Clear all messages from the chat view."""
         for widget in self._message_widgets:
             widget.remove()
         self._message_widgets.clear()
+        self._thinking_widget = None
         self.messages.clear()
 
 
-class InputBar(Horizontal):
+class ToolPanel(Container):
     """
-    Input bar with text input and submit button.
-    
-    Emits:
-        InputBar.Submitted: When user submits input
+    A dedicated panel for displaying running/completed tools.
+    Shows at the bottom of the chat when tools are active.
     """
-    
-    DEFAULT_CSS = """
-    InputBar {
-        height: auto;
-        border-top: solid $primary;
-        padding: 1;
-    }
-    
-    InputBar Input {
-        width: 1fr;
-    }
-    
-    InputBar Button {
-        margin-left: 1;
-    }
+
+    def __init__(self, **kwargs):
+        super().__init__(**kwargs)
+        # tool_call_id -> (widget, spinner, tool_name, args_str, is_done)
+        self._tools: dict[str, tuple[Static, Spinner | None, str, str, bool]] = {}
+
+    def compose(self) -> ComposeResult:
+        """Compose starts empty."""
+        return
+        yield
+
+    def on_mount(self) -> None:
+        """Start hidden - only show when tools are active."""
+        self.display = False
+
+    def add_tool(self, tool_call_id: str, tool_name: str, arguments: dict) -> None:
+        """Add a new running tool to the panel."""
+        self.display = True
+        args_str = self._format_preview(str(arguments), max_len=80)
+
+        tool_text = Text()
+        tool_text.append(f"{tool_name}", style="yellow")
+        tool_text.append(f" {args_str}", style="dim")
+
+        spinner = Spinner("aesthetic", text=tool_text, style="bold yellow")
+        widget = Static(spinner, classes="tool-item running")
+        self._tools[tool_call_id] = (widget, spinner, tool_name, args_str, False)
+        self.mount(widget)
+
+    def complete_tool(self, tool_call_id: str, result: str = "") -> None:
+        """Mark a tool as completed."""
+        if tool_call_id not in self._tools:
+            return
+
+        widget, _, tool_name, args_str, _ = self._tools[tool_call_id]
+        result_preview = self._format_preview(str(result), max_len=80)
+
+        text = Text()
+        text.append("✓ ", style="bold green")
+        text.append(f"{tool_name}", style="green")
+        if result_preview:
+            text.append(f" → {result_preview}", style="dim")
+
+        widget.update(text)
+        widget.remove_class("running")
+        widget.add_class("completed")
+        self._tools[tool_call_id] = (widget, None, tool_name, args_str, True)
+
+    def update_spinners(self) -> None:
+        """Re-render running tool spinners (they auto-advance based on time)."""
+        for tool_id, (widget, spinner, tool_name, args_str, is_done) in self._tools.items():
+            if not is_done and spinner is not None:
+                widget.update(spinner)
+
+    def _format_preview(self, text: str, max_len: int = 80) -> str:
+        """Format text to be a short preview."""
+        preview = text.replace("\n", " ").replace("  ", " ").strip()
+        if len(preview) > max_len:
+            preview = preview[:max_len - 3] + "..."
+        return preview
+
+    def clear_completed(self) -> None:
+        """Remove all completed tools."""
+        to_remove = [tid for tid, (_, _, _, _, is_done) in self._tools.items() if is_done]
+        for tool_id in to_remove:
+            widget, _, _, _, _ = self._tools[tool_id]
+            widget.remove()
+            del self._tools[tool_id]
+        if not self._tools:
+            self.display = False
+
+    def clear_all(self) -> None:
+        """Clear all tools from panel."""
+        for widget, _, _, _, _ in self._tools.values():
+            widget.remove()
+        self._tools.clear()
+        self.display = False
+
+
+class AutoCompleteInput(Input):
+    """
+    Input widget with slash command auto-completion.
+    Shows suggestions when user types '/'.
+    """
+
+    def __init__(self, commands: list[str], **kwargs):
+        self._commands = commands
+        suggester = SuggestFromList(commands, case_sensitive=False)
+        super().__init__(suggester=suggester, **kwargs)
+
+    def _show_suggestions(self) -> None:
+        """Override to only show suggestions for commands (starting with /)."""
+        if self.value.startswith("/"):
+            super()._show_suggestions()
+        else:
+            popup = getattr(self, "_suggestion_popup", None)
+            if popup is not None:
+                popup.display = False
+
+    def on_key(self, event) -> None:
+        """Handle key events for completion."""
+        if event.key == "tab" and self.value.startswith("/"):
+            event.prevent_default()
+            event.stop()
+            self._accept_suggestion()
+        elif event.key == "enter":
+            popup = getattr(self, "_suggestion_popup", None)
+            if popup is not None:
+                popup.display = False
+
+    def _accept_suggestion(self) -> None:
+        """Accept the current suggestion if available."""
+        if not self.value.startswith("/"):
+            return
+
+        suggestion = getattr(self, "_suggestion", None)
+        if suggestion:
+            self.value = suggestion
+            popup = getattr(self, "_suggestion_popup", None)
+            if popup is not None:
+                popup.display = False
+            self.cursor_position = len(self.value)
+        else:
+            self._show_suggestions()
+            suggestion = getattr(self, "_suggestion", None)
+            if suggestion:
+                self.value = suggestion
+                popup = getattr(self, "_suggestion_popup", None)
+                if popup is not None:
+                    popup.display = False
+                self.cursor_position = len(self.value)
+
+
+class CLIInputBar(Horizontal):
     """
-    
+    CLI-style input bar with prompt prefix and auto-completion.
+    """
+
     class Submitted(Message):
         """Message sent when input is submitted."""
-        
+
         def __init__(self, value: str) -> None:
             self.value = value
             super().__init__()
-    
-    def __init__(self, **kwargs):
+
+    def __init__(self, commands: list[str], **kwargs):
         super().__init__(**kwargs)
+        self.commands = commands
         self._input = None
-    
+        self._history_file = Path.home() / ".ayder_chat_history"
+        self._history: list[str] = self._load_history()
+        self._history_index: int = len(self._history)
+        self._current_input: str = ""
+
+    def _load_history(self) -> list[str]:
+        """Load command history from file (same file as CLI)."""
+        if self._history_file.exists():
+            try:
+                content = self._history_file.read_text(encoding="utf-8")
+                lines = [line.strip() for line in content.split("\n") if line.strip()]
+                return lines[-1000:]
+            except Exception:
+                pass
+        return []
+
+    def _save_to_history(self, command: str) -> None:
+        """Append command to history file."""
+        try:
+            with open(self._history_file, "a", encoding="utf-8") as f:
+                f.write(command + "\n")
+        except Exception:
+            pass
+
     def compose(self) -> ComposeResult:
         """Compose the input bar."""
-        self._input = Input(placeholder="Type your message...", id="chat-input")
+        yield Static(">", classes="prompt")
+        self._input = AutoCompleteInput(
+            self.commands,
+            placeholder="Type your message or /command...",
+            id="chat-input"
+        )
         yield self._input
-        yield Button("Send", id="send-btn", variant="primary")
-    
+
     def on_mount(self) -> None:
         """Focus input on mount."""
-        self._input = self.query_one("#chat-input", Input)
+        self._input = self.query_one("#chat-input", AutoCompleteInput)
         self._input.focus()
-    
+
     def on_input_submitted(self, event: Input.Submitted) -> None:
         """Handle Enter key in input."""
         self._submit()
-    
-    def on_button_pressed(self, event: Button.Pressed) -> None:
-        """Handle Send button click."""
-        if event.button.id == "send-btn":
-            self._submit()
-    
+
     def _submit(self) -> None:
         """Submit the current input value."""
         if self._input:
             value = self._input.value.strip()
             if value:
-                self.post_message(self.Submitted(value))
+                if not self._history or self._history[-1] != value:
+                    self._history.append(value)
+                    self._save_to_history(value)
+                self._history_index = len(self._history)
+                self._current_input = ""
+                popup = getattr(self._input, "_suggestion_popup", None)
+                if popup is not None:
+                    popup.display = False
+                self.app.post_message(self.Submitted(value))
                 self._input.value = ""
-    
+
     def focus_input(self) -> None:
         """Focus the input field."""
         if self._input:
             self._input.focus()
-    
+
     def set_enabled(self, enabled: bool) -> None:
         """Enable or disable input."""
         if self._input:
             self._input.disabled = not enabled
-        send_btn = self.query_one("#send-btn", Button)
-        if send_btn:
-            send_btn.disabled = not enabled
 
+    def on_key(self, event) -> None:
+        """Handle key events for history navigation and tab completion."""
+        if event.key == "up":
+            event.prevent_default()
+            event.stop()
+            self._history_navigate(-1)
+        elif event.key == "down":
+            event.prevent_default()
+            event.stop()
+            self._history_navigate(1)
+        elif event.key == "tab":
+            if self._input and self._input.value.startswith("/"):
+                event.prevent_default()
+                event.stop()
+                self._input._accept_suggestion()
+            else:
+                event.prevent_default()
+                event.stop()
+
+    def _history_navigate(self, direction: int) -> None:
+        """Navigate through command history.
 
-class ContextPanel(Vertical):
-    """
-    Sidebar panel showing context information:
-    - Active model
-    - Token usage
-    - Active files
-    - Project info
+        Args:
+            direction: -1 for up (older), 1 for down (newer)
+        """
+        if not self._history:
+            return
+
+        if self._history_index == len(self._history):
+            self._current_input = self._input.value
+
+        new_index = self._history_index + direction
+
+        if new_index < 0:
+            new_index = 0
+        if new_index > len(self._history):
+            new_index = len(self._history)
+
+        self._history_index = new_index
+
+        if self._history_index == len(self._history):
+            self._input.value = self._current_input
+        else:
+            self._input.value = self._history[self._history_index]
+
+        self._input.cursor_position = len(self._input.value)
+
+
+class StatusBar(Horizontal):
     """
-    
-    DEFAULT_CSS = """
-    ContextPanel {
-        width: 100%;
-        height: 100%;
-        border: solid $primary-darken-2;
-        padding: 1;
-    }
-    
-    ContextPanel .section-title {
-        text-style: bold;
-        color: $primary;
-        margin: 1 0;
-    }
-    
-    ContextPanel .info-row {
-        margin: 0 0 1 0;
-    }
-    
-    ContextPanel Tree {
-        height: 1fr;
-        border: none;
-        padding: 0;
-    }
+    CLI-style status bar showing context info.
     """
-    
+
     def __init__(self, model: str = "default", **kwargs):
         super().__init__(**kwargs)
         self.model = model
         self.token_count = 0
         self.active_files: list[str] = []
-        self._token_label = None
-        self._file_tree = None
-    
+
     def compose(self) -> ComposeResult:
-        """Compose the context panel."""
-        # Model info section
-        yield Label("Model", classes="section-title")
-        yield Label(f"  {self.model}", classes="info-row")
-        
-        # Token usage section
-        yield Label("Token Usage", classes="section-title")
-        self._token_label = Label("  0 tokens", classes="info-row")
-        yield self._token_label
-        
-        # Active files section
-        yield Label("Active Files", classes="section-title")
-        
-        # File tree
-        tree: Tree[dict] = Tree("Project")
-        tree.root.expand()
-        self._file_tree = tree
-        yield tree
-    
+        yield Label(f"model: {self.model}", id="model-label")
+        yield Label(f" | tokens: 0", id="token-label")
+        yield Label(f" | files: 0", id="files-label")
+        yield Static(classes="spacer")
+        yield Label("^C:copy ^X:cancel ^L:clear ^Q:quit", classes="key-hint")
+
     def set_model(self, model: str) -> None:
         """Update the displayed model."""
         self.model = model
-        # Update UI (would need to store reference to label)
-    
+        label = self.query_one("#model-label", Label)
+        label.update(f"model: {model}")
+
     def update_token_usage(self, count: int) -> None:
         """Update token count display."""
         self.token_count = count
-        if self._token_label:
-            self._token_label.update(f"  {count:,} tokens")
-    
-    def add_active_file(self, file_path: str) -> None:
-        """Add a file to the active files list."""
-        if file_path not in self.active_files:
-            self.active_files.append(file_path)
-            self._refresh_file_tree()
-    
-    def remove_active_file(self, file_path: str) -> None:
-        """Remove a file from the active files list."""
-        if file_path in self.active_files:
-            self.active_files.remove(file_path)
-            self._refresh_file_tree()
-    
-    def clear_active_files(self) -> None:
-        """Clear all active files."""
-        self.active_files.clear()
-        self._refresh_file_tree()
-    
-    def _refresh_file_tree(self) -> None:
-        """Refresh the file tree display."""
-        if not self._file_tree:
-            return
-        
-        self._file_tree.clear()
-        root = self._file_tree.root
-        root.label = "Active Files"
-        
-        for file_path in self.active_files:
-            root.add_leaf(file_path)
+        label = self.query_one("#token-label", Label)
+        label.update(f" | tokens: {count:,}")
+
+    def update_files(self, files: list[str]) -> None:
+        """Update active files count."""
+        self.active_files = files
+        label = self.query_one("#files-label", Label)
+        label.update(f" | files: {len(files)}")
 
 
 class AyderApp(App):
     """
-    Main Textual application for ayder-cli with integrated LLM agent.
-    
+    Main CLI-style application for ayder-cli.
+
     Layout:
-    - Header: App title and current model
-    - Main area: Chat view (left) + Context panel (right)
-    - Footer: Status info and keyboard shortcuts
+    - Banner at top (compact, not full screen)
+    - Main area: Chat view
+    - Input bar: CLI prompt style at bottom
+    - Status bar: Context info at very bottom
     """
-    
-    CSS = """
-    /* Screen layout */
-    Screen {
-        layout: vertical;
-    }
-    
-    /* Main container */
-    #main-container {
-        layout: horizontal;
-        height: 1fr;
-    }
-    
-    /* Chat view takes most space */
-    #chat-view {
-        width: 3fr;
-        height: 100%;
-        border: solid $primary;
-    }
-    
-    /* Context panel on the right */
-    #context-panel {
-        width: 1fr;
-        height: 100%;
-        border: solid $primary-darken-2;
-    }
-    
-    /* Input area at bottom */
-    #input-bar {
-        height: auto;
-        border-top: solid $primary;
-        padding: 1;
-    }
-    """
-    
+
+    CSS = get_theme_css()
+
     BINDINGS = [
         ("ctrl+q", "quit", "Quit"),
-        ("ctrl+c", "cancel", "Cancel"),
+        ("ctrl+x", "cancel", "Cancel"),
+        ("ctrl+c", "copy_selection", "Copy"),
         ("ctrl+l", "clear", "Clear Chat"),
+        ("ctrl+d", "exit_prompt", "Exit"),
     ]
-    
+
     def __init__(self, model: str = "default", safe_mode: bool = False, **kwargs):
         """
         Initialize the TUI app.
-        
+
         Args:
             model: The LLM model name to use
-            safe_mode: Whether to enable safe mode (blocks destructive operations)
-            **kwargs: Additional arguments for App
+            safe_mode: Whether to enable safe mode
         """
         super().__init__(**kwargs)
         self.model = model
         self.safe_mode = safe_mode
-        self.title = f"Ayder CLI - {model}"
-        
-        # Load config
+
+        self._ctrl_d_pressed = False
+        self._ctrl_d_timer = None
+
+        self._pending_messages: list[str] = []
+        self._is_processing = False
+
         self.config = load_config()
-        
-        # Initialize OpenAI client
+
         if isinstance(self.config, dict):
             base_url = self.config.get("base_url", "http://localhost:11434/v1")
             api_key = self.config.get("api_key", "ollama")
+            actual_model = self.config.get("model", model)
         else:
             base_url = self.config.base_url
             api_key = self.config.api_key
-        
+            actual_model = self.config.model
+
+        self.model = actual_model if actual_model != "default" else model
         self.llm = OpenAIProvider(base_url=base_url, api_key=api_key)
-        
-        # Conversation history
+
         self.messages: list[dict] = []
-        
-        # Tool registry with callbacks and middleware
+
+        registry = get_registry()
+        self.commands = registry.get_command_names()
+
         self.registry = create_default_registry(ProjectContext("."))
         self._setup_registry_callbacks()
         self._setup_registry_middleware()
-    
+
+        self._thinking_timer: Timer | None = None
+        self._tools_timer: Timer | None = None
+        self._total_tokens: int = 0
+
+    def _animate_running_tools(self) -> None:
+        """Animate spinner for running tools."""
+        tool_panel = self.query_one("#tool-panel", ToolPanel)
+        tool_panel.update_spinners()
+
     def _setup_registry_callbacks(self) -> None:
         """Setup callbacks for tool registry."""
-        # Pre-execute callback
         def on_tool_start(tool_name: str, arguments: dict):
             chat_view = self.query_one("#chat-view", ChatView)
             chat_view.add_tool_call(tool_name, str(arguments))
-        
-        # Post-execute callback
+
         def on_tool_complete(result):
             chat_view = self.query_one("#chat-view", ChatView)
             if result.result:
                 chat_view.add_tool_result(result.result)
-        
+
         self.registry.add_pre_execute_callback(on_tool_start)
         self.registry.add_post_execute_callback(on_tool_complete)
-    
+
     def _setup_registry_middleware(self) -> None:
-        """Setup middleware for safe mode and confirmations."""
-        # Safe mode middleware
+        """Setup middleware for safe mode."""
         def safe_mode_check(tool_name: str, arguments: dict):
             if self._is_tool_blocked_in_safe_mode(tool_name):
-                # Show safe mode block screen (synchronous for now)
-                # In a real async implementation, this would need to be awaited
-                # For now, we'll raise PermissionError which will be caught by the registry
                 raise PermissionError(f"Tool '{tool_name}' blocked in safe mode")
-        
+
         if self.safe_mode:
             self.registry.add_middleware(safe_mode_check)
-    
-    def _is_tool_blocked_in_safe_mode(self, tool_name: str) -> bool:
-        """
-        Check if a tool should be blocked in safe mode.
 
-        Args:
-            tool_name: Name of the tool
-
-        Returns:
-            True if tool should be blocked
-        """
+    def _is_tool_blocked_in_safe_mode(self, tool_name: str) -> bool:
+        """Check if a tool should be blocked in safe mode."""
         from ayder_cli.tools.definition import TOOL_DEFINITIONS_BY_NAME
 
         tool_def = TOOL_DEFINITIONS_BY_NAME.get(tool_name)
         return tool_def.safe_mode_blocked if tool_def else False
-    
+
     def compose(self) -> ComposeResult:
-        """
-        Compose the UI layout.
-        
-        Yields:
-            UI components
-        """
-        # Header with title
-        yield Header(show_clock=True)
-        
-        # Main content area
-        with Horizontal(id="main-container"):
-            # Chat view
-            yield ChatView(id="chat-view")
-            
-            # Context panel
-            yield ContextPanel(model=self.model, id="context-panel")
-        
-        # Input bar
-        yield InputBar(id="input-bar")
-        
-        # Footer with shortcuts
-        yield Footer()
-    
+        """Compose the UI layout - terminal style with scrolling content."""
+        yield ChatView(id="chat-view")
+        yield ToolPanel(id="tool-panel")
+        yield CLIInputBar(commands=self.commands, id="input-bar")
+        yield StatusBar(model=self.model, id="status-bar")
+
     def on_mount(self) -> None:
         """Called when app is mounted."""
-        self.title = f"Ayder CLI - {self.model}"
-        
-        # Show welcome message
+        self.title = f"ayder - {self.model}"
+
+        # Show the banner as scrollable content in the chat view
         chat_view = self.query_one("#chat-view", ChatView)
-        chat_view.add_system_message("Welcome to Ayder CLI! Type your message to begin.")
-    
-    def on_input_bar_submitted(self, event: InputBar.Submitted) -> None:
+        banner = create_tui_banner(self.model)
+        chat_view.mount(Static(banner, classes="banner-content"))
+
+    @on(CLIInputBar.Submitted)
+    def handle_input_submitted(self, event: CLIInputBar.Submitted) -> None:
         """Handle user input submission."""
         user_input = event.value
-        
-        # Add to chat view
+
+        if user_input.startswith("/"):
+            self._handle_command(user_input)
+            return
+
+        self._pending_messages.append(user_input)
+
+        if not self._is_processing:
+            self._process_next_message()
+
+    def _process_next_message(self) -> None:
+        """Process the next pending message."""
+        if not self._pending_messages:
+            self._is_processing = False
+            return
+
+        self._is_processing = True
+        user_input = self._pending_messages.pop(0)
+
         chat_view = self.query_one("#chat-view", ChatView)
         chat_view.add_user_message(user_input)
-        
-        # Add to conversation history
+
         self.messages.append({"role": "user", "content": user_input})
-        
-        # Disable input during processing
-        input_bar = self.query_one("#input-bar", InputBar)
+
+        chat_view.show_thinking()
+        self._thinking_timer = self.set_interval(0.1, self._animate_thinking)
+
+        self.run_worker(self._process_llm_response(), exclusive=True)
+
+    def _animate_thinking(self) -> None:
+        """Animate the thinking indicator."""
+        chat_view = self.query_one("#chat-view", ChatView)
+        chat_view._update_thinking()
+
+    def _handle_command(self, cmd: str) -> None:
+        """Handle slash commands - display output in TUI."""
+        from ayder_cli.core.context import SessionContext
+
+        chat_view = self.query_one("#chat-view", ChatView)
+        chat_view.add_user_message(cmd)
+
+        parts = cmd.split(None, 1)
+        cmd_name = parts[0].lower()
+        cmd_args = parts[1] if len(parts) > 1 else ""
+
+        try:
+            if cmd_name == "/help":
+                self._show_help(chat_view)
+            elif cmd_name == "/model":
+                self._handle_model_command(cmd_args, chat_view)
+            elif cmd_name == "/tasks":
+                self._handle_tasks_command(chat_view)
+            elif cmd_name == "/tools":
+                self._handle_tools_command(chat_view)
+            elif cmd_name == "/verbose":
+                self._handle_verbose_command(chat_view)
+            elif cmd_name == "/compact":
+                self._handle_compact_command(chat_view)
+            elif cmd_name == "/plan":
+                self._handle_plan_command(cmd_args, chat_view)
+            elif cmd_name == "/ask":
+                self._handle_ask_command(cmd_args, chat_view)
+            elif cmd_name == "/implement":
+                self._handle_implement_command(cmd_args, chat_view)
+            elif cmd_name == "/implement-all":
+                self._handle_implement_all_command(chat_view)
+            elif cmd_name == "/task-edit":
+                self._handle_task_edit_command(cmd_args, chat_view)
+            elif cmd_name == "/archive-completed-tasks":
+                self._handle_archive_command(chat_view)
+            else:
+                chat_view.add_system_message(f"Unknown command: {cmd_name}. Type /help for available commands.")
+        except Exception as e:
+            chat_view.add_system_message(f"Command error: {type(e).__name__}: {e}")
+
+    def _show_help(self, chat_view: ChatView) -> None:
+        """Show help message in TUI."""
+        registry = get_registry()
+        commands = registry.list_commands()
+        commands.sort(key=lambda c: c.name)
+
+        help_text = "[bold]Available Commands:[/bold]\n"
+        for cmd in commands:
+            help_text += f"  [cyan]{cmd.name:<20}[/cyan] {cmd.description}\n"
+
+        chat_view.add_assistant_message(help_text)
+
+    def _do_clear(self, chat_view: ChatView) -> None:
+        """Clear conversation history."""
+        if self.messages:
+            if self.messages[0].get("role") == "system":
+                system_msg = self.messages[0]
+                self.messages.clear()
+                self.messages.append(system_msg)
+            else:
+                self.messages.clear()
+
+        chat_view.clear_messages()
+        chat_view.add_system_message("Conversation history cleared.")
+
+    def _handle_model_command(self, args: str, chat_view: ChatView) -> None:
+        """Handle /model command."""
+        if not args.strip():
+            try:
+                models = self.llm.list_models()
+                if not models:
+                    chat_view.add_system_message(f"Current model: {self.model}")
+                    return
+
+                # Show interactive select screen
+                items = [(m, m) for m in sorted(models)]
+
+                def on_model_selected(selected: str | None) -> None:
+                    if selected:
+                        self.model = selected
+                        status_bar = self.query_one("#status-bar", StatusBar)
+                        status_bar.set_model(selected)
+                        chat_view.add_system_message(f"Switched to model: {selected}")
+
+                self.push_screen(
+                    CLISelectScreen(
+                        title="Select model",
+                        items=items,
+                        current=self.model,
+                        description=f"Currently using: {self.model}"
+                    ),
+                    on_model_selected
+                )
+            except Exception as e:
+                chat_view.add_system_message(f"Error listing models: {e}")
+        else:
+            new_model = args.strip()
+            self.model = new_model
+            status_bar = self.query_one("#status-bar", StatusBar)
+            status_bar.set_model(new_model)
+            chat_view.add_system_message(f"Switched to model: {new_model}")
+
+    def _handle_tasks_command(self, chat_view: ChatView) -> None:
+        """Handle /tasks command."""
+        from ayder_cli.tasks import _get_tasks_dir, _get_task_path_by_id, _parse_title, _extract_id
+
+        try:
+            project_ctx = ProjectContext(".")
+            tasks_dir = _get_tasks_dir(project_ctx)
+
+            if not tasks_dir.exists():
+                chat_view.add_system_message("No tasks directory found. Create tasks first with /plan.")
+                return
+
+            # Build list of tasks
+            items = []
+            task_paths = {}  # Map display text to task path
+
+            for task_file in sorted(tasks_dir.glob("*.md")):
+                task_id = _extract_id(task_file.name)
+                if task_id is None:
+                    continue
+
+                title = _parse_title(task_file)
+                content = task_file.read_text(encoding="utf-8")
+
+                # Determine status
+                status = "pending"
+                if "- **status:** done" in content.lower():
+                    status = "done"
+                elif "- **status:** in_progress" in content.lower():
+                    status = "in_progress"
+
+                # Format display with status indicator
+                status_icon = "✓" if status == "done" else "○" if status == "pending" else "◐"
+                display = f"TASK-{task_id:03d}: {title} [{status_icon}]"
+
+                items.append((str(task_id), display))
+                task_paths[str(task_id)] = task_file
+
+            if not items:
+                chat_view.add_system_message("No tasks found. Create tasks first with /plan.")
+                return
+
+            def on_task_selected(selected: str | None) -> None:
+                if selected:
+                    task_id = int(selected)
+                    task_path = task_paths.get(selected)
+                    if task_path:
+                        title = _parse_title(task_path)
+                        self._run_implement_task(task_id, title, chat_view)
+
+            self.push_screen(
+                CLISelectScreen(
+                    title="Select task to implement",
+                    items=items,
+                    description=f"{len(items)} task(s) found • Enter to implement • Esc to cancel"
+                ),
+                on_task_selected
+            )
+
+        except Exception as e:
+            chat_view.add_system_message(f"Error listing tasks: {e}")
+
+    def _handle_tools_command(self, chat_view: ChatView) -> None:
+        """Handle /tools command - list all available tools."""
+        from ayder_cli.tools.schemas import tools_schema
+
+        try:
+            if not tools_schema:
+                chat_view.add_system_message("No tools available.")
+                return
+
+            tools_text = "[bold]Available Tools:[/bold]\n\n"
+            for tool in tools_schema:
+                func = tool.get('function', {})
+                name = func.get('name', 'Unknown')
+                desc = func.get('description', 'No description provided.')
+                # Truncate long descriptions
+                if len(desc) > 100:
+                    desc = desc[:100] + "..."
+                tools_text += f"  [cyan]{name}[/cyan]: {desc}\n"
+
+            chat_view.add_assistant_message(tools_text)
+        except Exception as e:
+            chat_view.add_system_message(f"Error listing tools: {e}")
+
+    def _run_implement_task(self, task_id: int, title: str, chat_view) -> None:
+        """Run a single task implementation."""
+        from ayder_cli.tasks import _get_task_path_by_id
+        from ayder_cli.prompts import TASK_EXECUTION_PROMPT_TEMPLATE
+
+        project_ctx = ProjectContext(".")
+        task_path = _get_task_path_by_id(project_ctx, task_id)
+
+        if task_path is None:
+            chat_view.add_system_message(f"Task TASK-{task_id:03d} not found.")
+            return
+
+        rel_path = project_ctx.to_relative(task_path)
+        command = TASK_EXECUTION_PROMPT_TEMPLATE.format(task_path=rel_path)
+        self.messages.append({"role": "user", "content": command})
+        chat_view.add_system_message(f"Running TASK-{task_id:03d}: {title}")
+
+        input_bar = self.query_one("#input-bar", CLIInputBar)
         input_bar.set_enabled(False)
-        
-        # Start LLM worker
+        chat_view.show_thinking()
+        self._thinking_timer = self.set_interval(0.1, self._animate_thinking)
         self.run_worker(self._process_llm_response(), exclusive=True)
-    
-    async def _process_llm_response(self) -> None:
-        """
-        Process LLM response (runs in worker thread).
-        
-        This runs asynchronously to not block the UI.
-        """
+
+    def _handle_verbose_command(self, chat_view: ChatView) -> None:
+        """Handle /verbose command."""
+        current = getattr(self, '_verbose_mode', False)
+        self._verbose_mode = not current
+        status = "ON" if self._verbose_mode else "OFF"
+        chat_view.add_system_message(f"Verbose mode: {status}")
+
+    def _handle_compact_command(self, chat_view: ChatView) -> None:
+        """Handle /compact command."""
+        from ayder_cli.prompts import COMPACT_PROMPT_TEMPLATE
+
+        if len(self.messages) <= 1:
+            chat_view.add_system_message("No conversation to compact.")
+            return
+
+        conversation_text = ""
+        for msg in self.messages:
+            if msg.get("role") in ("user", "assistant"):
+                role = msg.get("role", "unknown")
+                content = msg.get("content", "")
+                conversation_text += f"[{role}] {content}\n\n"
+
+        system_msg = None
+        if self.messages and self.messages[0].get("role") == "system":
+            system_msg = self.messages[0]
+        self.messages.clear()
+        if system_msg:
+            self.messages.append(system_msg)
+
+        compact_prompt = COMPACT_PROMPT_TEMPLATE.format(conversation_text=conversation_text)
+        self.messages.append({"role": "user", "content": compact_prompt})
+        chat_view.add_system_message("Compacting: summarize → save → clear → load")
+
+        input_bar = self.query_one("#input-bar", CLIInputBar)
+        input_bar.set_enabled(False)
+        chat_view.show_thinking()
+        self._thinking_timer = self.set_interval(0.1, self._animate_thinking)
+        self.run_worker(self._process_llm_response(), exclusive=True)
+
+    def _handle_plan_command(self, args: str, chat_view: ChatView) -> None:
+        """Handle /plan command."""
+        from ayder_cli.prompts import PLANNING_PROMPT_TEMPLATE
+
+        if not args.strip():
+            chat_view.add_system_message("Usage: /plan <task description>\nExample: /plan Implement user authentication")
+            return
+
+        planning_prompt = PLANNING_PROMPT_TEMPLATE.format(task_description=args.strip())
+        self.messages.append({"role": "user", "content": planning_prompt})
+        chat_view.add_system_message(f"Planning: {args.strip()[:50]}...")
+
+        input_bar = self.query_one("#input-bar", CLIInputBar)
+        input_bar.set_enabled(False)
+        chat_view.show_thinking()
+        self._thinking_timer = self.set_interval(0.1, self._animate_thinking)
+        self.run_worker(self._process_llm_response(), exclusive=True)
+
+    def _handle_ask_command(self, args: str, chat_view: ChatView) -> None:
+        """Handle /ask command."""
+        if not args.strip():
+            chat_view.add_system_message("Usage: /ask <question>\nExample: /ask What is Python?")
+            return
+
+        self._no_tools_for_next = True
+        self.messages.append({"role": "user", "content": args.strip()})
+        chat_view.add_user_message(args.strip())
+
+        input_bar = self.query_one("#input-bar", CLIInputBar)
+        input_bar.set_enabled(False)
+        chat_view.show_thinking()
+        self._thinking_timer = self.set_interval(0.1, self._animate_thinking)
+        self.run_worker(self._process_llm_response(no_tools=True), exclusive=True)
+
+    def _handle_implement_command(self, args: str, chat_view: ChatView) -> None:
+        """Handle /implement command."""
+        from ayder_cli.tasks import _get_tasks_dir, _get_task_path_by_id, _parse_title, _extract_id
+        from ayder_cli.prompts import TASK_EXECUTION_PROMPT_TEMPLATE
+
+        if not args.strip():
+            chat_view.add_system_message("Usage: /implement <task_id|name|pattern>\nExample: /implement 001")
+            return
+
+        project_ctx = ProjectContext(".")
+        tasks_dir = _get_tasks_dir(project_ctx)
+        query = args.strip()
+
+        try:
+            task_id = int(query)
+            task_path = _get_task_path_by_id(project_ctx, task_id)
+            if task_path:
+                title = _parse_title(task_path)
+                rel_path = project_ctx.to_relative(task_path)
+                command = TASK_EXECUTION_PROMPT_TEMPLATE.format(task_path=rel_path)
+                self.messages.append({"role": "user", "content": command})
+                chat_view.add_system_message(f"Running TASK-{task_id:03d}: {title}")
+
+                chat_view.show_thinking()
+                self._thinking_timer = self.set_interval(0.1, self._animate_thinking)
+                self.run_worker(self._process_llm_response(), exclusive=True)
+                return
+        except ValueError:
+            pass
+
+        matching = []
+        query_lower = query.lower()
+        for task_file in sorted(tasks_dir.glob("*.md")):
+            task_id = _extract_id(task_file.name)
+            if task_id is None:
+                continue
+            title = _parse_title(task_file)
+            if query_lower in title.lower():
+                matching.append((task_id, task_file, title))
+
+        if not matching:
+            chat_view.add_system_message(f"No tasks found matching: {query}")
+            return
+
+        for task_id, task_path, title in matching:
+            rel_path = project_ctx.to_relative(task_path)
+            command = TASK_EXECUTION_PROMPT_TEMPLATE.format(task_path=rel_path)
+            self.messages.append({"role": "user", "content": command})
+
+        chat_view.add_system_message(f"Running {len(matching)} matching task(s)...")
+
+        input_bar = self.query_one("#input-bar", CLIInputBar)
+        input_bar.set_enabled(False)
+        chat_view.show_thinking()
+        self._thinking_timer = self.set_interval(0.1, self._animate_thinking)
+        self.run_worker(self._process_llm_response(), exclusive=True)
+
+    def _handle_implement_all_command(self, chat_view: ChatView) -> None:
+        """Handle /implement-all command."""
+        from ayder_cli.tasks import _get_tasks_dir, _extract_id, _parse_title
+        from ayder_cli.prompts import TASK_EXECUTION_ALL_PROMPT_TEMPLATE
+
+        project_ctx = ProjectContext(".")
+        tasks_dir = _get_tasks_dir(project_ctx)
+
+        if not tasks_dir.exists():
+            chat_view.add_system_message("No tasks directory found. Create tasks first with /plan.")
+            return
+
+        pending = []
+        for task_file in sorted(tasks_dir.glob("*.md")):
+            task_id = _extract_id(task_file.name)
+            if task_id is None:
+                continue
+            content = task_file.read_text(encoding="utf-8")
+            if "- **status:** pending" in content.lower() or "- **status:** todo" in content.lower():
+                title = _parse_title(task_file)
+                pending.append((task_id, title))
+
+        if not pending:
+            chat_view.add_system_message("No pending tasks found. All tasks are complete!")
+            return
+
+        task_list = "\n".join([f"  - TASK-{tid:03d}: {title}" for tid, title in pending])
+        chat_view.add_system_message(f"Implementing {len(pending)} pending tasks:\n{task_list}")
+
+        self.messages.append({"role": "user", "content": TASK_EXECUTION_ALL_PROMPT_TEMPLATE})
+
+        input_bar = self.query_one("#input-bar", CLIInputBar)
+        input_bar.set_enabled(False)
+        chat_view.show_thinking()
+        self._thinking_timer = self.set_interval(0.1, self._animate_thinking)
+        self.run_worker(self._process_llm_response(), exclusive=True)
+
+    def _handle_task_edit_command(self, args: str, chat_view: ChatView) -> None:
+        """Handle /task-edit command."""
+        import subprocess
+        from ayder_cli.tasks import _get_task_path_by_id
+
+        if not args.strip():
+            chat_view.add_system_message("Usage: /task-edit <task_id>\nExample: /task-edit 1")
+            return
+
+        try:
+            task_id = int(args.strip())
+        except ValueError:
+            chat_view.add_system_message(f"Invalid task ID: {args.strip()}")
+            return
+
+        project_ctx = ProjectContext(".")
+        task_path = _get_task_path_by_id(project_ctx, task_id)
+
+        if task_path is None:
+            chat_view.add_system_message(f"Task TASK-{task_id:03d} not found.")
+            return
+
+        if isinstance(self.config, dict):
+            editor = self.config.get("editor", "vim")
+        else:
+            editor = self.config.editor
+
+        try:
+            subprocess.run([editor, str(task_path)], check=True)
+            chat_view.add_system_message(f"Task TASK-{task_id:03d} edited successfully.")
+        except Exception as e:
+            chat_view.add_system_message(f"Error opening editor: {e}")
+
+    def _handle_archive_command(self, chat_view: ChatView) -> None:
+        """Handle /archive-completed-tasks command."""
+        import shutil
+        from ayder_cli.tasks import _get_tasks_dir, _extract_id, _parse_title
+
+        project_ctx = ProjectContext(".")
+        tasks_dir = _get_tasks_dir(project_ctx)
+
+        if not tasks_dir.exists():
+            chat_view.add_system_message("No tasks directory found.")
+            return
+
+        archive_dir = tasks_dir.parent / "task_archive"
+        archived = []
+
+        for task_file in sorted(tasks_dir.glob("*.md")):
+            task_id = _extract_id(task_file.name)
+            if task_id is None:
+                continue
+            content = task_file.read_text(encoding="utf-8")
+            if "- **status:** done" in content.lower():
+                title = _parse_title(task_file)
+                archive_dir.mkdir(parents=True, exist_ok=True)
+                shutil.move(str(task_file), str(archive_dir / task_file.name))
+                archived.append((task_id, title))
+
+        if not archived:
+            chat_view.add_system_message("No completed tasks to archive.")
+        else:
+            lines = "\n".join(f"  TASK-{tid:03d}: {title}" for tid, title in archived)
+            chat_view.add_system_message(f"Archived {len(archived)} completed task(s):\n{lines}")
+
+    async def _process_llm_response(self, no_tools: bool = False) -> None:
+        """Process LLM response (runs in worker thread)."""
         worker = get_current_worker()
-        
+
         try:
-            # Get tool schemas
-            tool_schemas = self.registry.get_schemas()
-            
-            # Get model config
+            tool_schemas = [] if no_tools else self.registry.get_schemas()
+
             if isinstance(self.config, dict):
                 model = self.config.get("model", "qwen3-coder:latest")
                 num_ctx = self.config.get("num_ctx", 65536)
             else:
                 model = self.config.model
                 num_ctx = self.config.num_ctx
-            
-            # Call LLM
+
             response = await call_llm_async(
                 self.llm,
                 self.messages,
@@ -706,42 +1298,43 @@ class AyderApp(App):
                 tools=tool_schemas,
                 num_ctx=num_ctx
             )
-            
-            # Handle response
+
             if worker.is_cancelled:
                 return
-            
+
             await self._handle_llm_response(response)
-            
+
         except Exception as e:
             if not worker.is_cancelled:
                 chat_view = self.query_one("#chat-view", ChatView)
                 chat_view.add_system_message(f"Error: {str(e)}")
         finally:
             if not worker.is_cancelled:
-                # Re-enable input
-                self.call_later(self._enable_input)
-    
+                self.call_later(self._finish_processing)
+
     async def _handle_llm_response(self, response) -> None:
-        """
-        Handle the LLM response, including tool calls.
-        
-        Args:
-            response: LLM response object
-        """
-        # Extract message
+        """Handle the LLM response, including tool calls."""
         message = response.choices[0].message
         content = message.content or ""
         tool_calls = message.tool_calls
-        
-        # Build message dict for history
+
+        # Update token counter from usage stats
+        usage = getattr(response, "usage", None)
+        if usage:
+            tokens = getattr(usage, "total_tokens", 0) or 0
+            self._total_tokens += tokens
+            self.call_later(
+                lambda t=self._total_tokens: self.query_one(
+                    "#status-bar", StatusBar
+                ).update_token_usage(t)
+            )
+
         msg_dict = {
             "role": "assistant",
             "content": content
         }
-        
+
         if tool_calls:
-            # Convert tool calls to dict format for history
             msg_dict["tool_calls"] = [
                 {
                     "id": tc.id,
@@ -753,77 +1346,185 @@ class AyderApp(App):
                 }
                 for tc in tool_calls
             ]
-        
-        # Add assistant message to history
+
         self.messages.append(msg_dict)
-        
-        # Display content
-        if content:
+
+        if content.strip():
             chat_view = self.query_one("#chat-view", ChatView)
             chat_view.add_assistant_message(content)
-        
-        # Execute tool calls
+
         if tool_calls:
+            tool_panel = self.query_one("#tool-panel", ToolPanel)
+
+            # Show all tools as running first
             for tool_call in tool_calls:
                 tool_name = tool_call.function.name
                 arguments = tool_call.function.arguments
-                
-                # Parse arguments if they're a string
-                import json
                 if isinstance(arguments, str):
                     arguments = json.loads(arguments)
-                
-                # Execute tool
-                result = self.registry.execute(tool_name, arguments)
-                
-                # Add tool result to messages
-                self.messages.append({
-                    "role": "tool",
+                tool_panel.add_tool(tool_call.id, tool_name, arguments)
+
+            # Start spinner animation for running tools
+            self._tools_timer = self.set_interval(0.1, self._animate_running_tools)
+
+            # Execute tool calls in parallel using asyncio.gather
+            async def execute_tool_async(tool_call):
+                """Execute a single tool call asynchronously."""
+                tool_name = tool_call.function.name
+                arguments = tool_call.function.arguments
+
+                if isinstance(arguments, str):
+                    arguments = json.loads(arguments)
+
+                # Run the synchronous tool in a thread pool
+                result = await asyncio.to_thread(
+                    self.registry.execute,
+                    tool_name,
+                    arguments
+                )
+
+                return {
                     "tool_call_id": tool_call.id,
                     "name": tool_name,
-                    "content": str(result)
-                })
-            
-            # Check if we should continue the conversation
+                    "result": result
+                }
+
+            # Execute all tools concurrently
+            tool_tasks = [execute_tool_async(tc) for tc in tool_calls]
+            tool_results = await asyncio.gather(*tool_tasks, return_exceptions=True)
+
+            # Stop the spinner timer
+            if self._tools_timer:
+                self._tools_timer.stop()
+                self._tools_timer = None
+
+            # Process results and mark tools as complete
+            for result_data in tool_results:
+                if isinstance(result_data, Exception):
+                    # Handle exceptions from tool execution
+                    error_msg = f"Error: {str(result_data)}"
+                    self.messages.append({
+                        "role": "tool",
+                        "tool_call_id": "error",
+                        "name": "unknown",
+                        "content": error_msg
+                    })
+                else:
+                    tool_call_id = result_data["tool_call_id"]
+                    result = result_data["result"]
+
+                    # Mark tool as complete in panel
+                    self.call_later(
+                        lambda tid=tool_call_id, res=result: tool_panel.complete_tool(tid, str(res))
+                    )
+
+                    self.messages.append({
+                        "role": "tool",
+                        "tool_call_id": tool_call_id,
+                        "name": result_data["name"],
+                        "content": str(result)
+                    })
+
+            # Schedule panel cleanup after a short delay
+            self.set_timer(2.0, lambda: tool_panel.clear_completed())
+
             worker = get_current_worker()
             if not worker.is_cancelled:
-                # Recursive call for follow-up
                 await self._process_llm_response()
-    
+
+    def _finish_processing(self) -> None:
+        """Finish processing - hide thinking indicator and process next message."""
+        if self._thinking_timer:
+            self._thinking_timer.stop()
+            self._thinking_timer = None
+
+        chat_view = self.query_one("#chat-view", ChatView)
+        chat_view.hide_thinking()
+
+        input_bar = self.query_one("#input-bar", CLIInputBar)
+        input_bar.set_enabled(True)
+        input_bar.focus_input()
+
+        if self._pending_messages:
+            self._process_next_message()
+        else:
+            self._is_processing = False
+
     def _enable_input(self) -> None:
-        """Re-enable input (called from worker thread)."""
-        input_bar = self.query_one("#input-bar", InputBar)
+        """Ensure input is enabled (called from worker thread)."""
+        input_bar = self.query_one("#input-bar", CLIInputBar)
         input_bar.set_enabled(True)
         input_bar.focus_input()
-    
+
     def action_cancel(self) -> None:
         """Cancel current operation."""
-        # Cancel any running workers
+        if self._thinking_timer:
+            self._thinking_timer.stop()
+            self._thinking_timer = None
+
+        if self._tools_timer:
+            self._tools_timer.stop()
+            self._tools_timer = None
+
         for worker in self.workers:
             worker.cancel()
-        
+
+        chat_view = self.query_one("#chat-view", ChatView)
+        chat_view.hide_thinking()
+
+        pending_count = len(self._pending_messages)
+        self._pending_messages.clear()
+        self._is_processing = False
+
         self._enable_input()
-        
+        if pending_count > 0:
+            chat_view.add_system_message(f"Operation cancelled ({pending_count} pending messages cleared).")
+        else:
+            chat_view.add_system_message("Operation cancelled.")
+
+    def action_exit_prompt(self) -> None:
+        """Handle Ctrl+D - press twice to exit."""
         chat_view = self.query_one("#chat-view", ChatView)
-        chat_view.add_system_message("Operation cancelled.")
-    
+
+        if self._ctrl_d_pressed:
+            chat_view.add_system_message("Goodbye!")
+            self.exit()
+        else:
+            self._ctrl_d_pressed = True
+            chat_view.add_system_message("Press Ctrl+D again to exit")
+            self._ctrl_d_timer = self.set_timer(3.0, self._reset_ctrl_d)
+
+    def _reset_ctrl_d(self) -> None:
+        """Reset the Ctrl+D press state."""
+        self._ctrl_d_pressed = False
+        self._ctrl_d_timer = None
+
+    def action_copy_selection(self) -> None:
+        """Copy selected text to clipboard, or cancel if nothing selected."""
+        text = self.screen.get_selected_text()
+        if text:
+            self.copy_to_clipboard(text)
+            self.screen.clear_selection()
+        else:
+            # No selection — fall back to cancel so Ctrl+C
+            # still interrupts when nothing is selected
+            self.action_cancel()
+
     def action_clear(self) -> None:
         """Clear chat history."""
         chat_view = self.query_one("#chat-view", ChatView)
-        chat_view.clear_messages()
-        self.messages.clear()
-        
-        chat_view.add_system_message("Chat history cleared.")
+        self._do_clear(chat_view)
 
 
-def run_tui(model: str = "default") -> None:
+def run_tui(model: str = "default", safe_mode: bool = False) -> None:
     """
-    Run the Textual TUI application.
-    
+    Run the CLI-style TUI application.
+
     Args:
         model: The LLM model name to use
+        safe_mode: Whether to enable safe mode
     """
-    app = AyderApp(model=model)
+    app = AyderApp(model=model, safe_mode=safe_mode)
     app.run()
 
 
diff --git a/tests/client/test_client.py b/tests/client/test_client.py
index 5589189..f666907 100644
--- a/tests/client/test_client.py
+++ b/tests/client/test_client.py
@@ -32,6 +32,7 @@ class TestChatSession:
             "iterations": 50,
         }
         assert session.session is None
+        assert session.checkpoint_manager is None
 
     def test_session_initialization_with_options(self):
         """Test ChatSession initialization with permissions and iterations."""
@@ -49,6 +50,23 @@ class TestChatSession:
         assert session.state["iterations"] == 5
         assert session.state["verbose"] is True
 
+    def test_session_initialization_with_checkpoint_manager(self):
+        """Test ChatSession initialization with checkpoint_manager."""
+        from ayder_cli.checkpoint_manager import CheckpointManager
+        from ayder_cli.core.context import ProjectContext
+        
+        config = Config(
+            base_url="http://test.com",
+            api_key="test-key",
+            model="test-model",
+            num_ctx=4096,
+            verbose=False
+        )
+        mock_cm = CheckpointManager(ProjectContext("."))
+        session = ChatSession(config, "prompt", checkpoint_manager=mock_cm)
+        
+        assert session.checkpoint_manager is mock_cm
+
     def test_session_add_message(self):
         """Test adding messages to history."""
         config = Config(
@@ -347,7 +365,7 @@ class TestAgent:
         # Check delegation
         mock_executor.execute_tool_calls.assert_called_once()
 
-    @patch("ayder_cli.client.parse_custom_tool_calls")
+    @patch("ayder_cli.chat_loop.parse_custom_tool_calls")
     def test_agent_chat_delegates_custom_calls(self, mock_parse):
         """Test agent delegates custom tool calls to ToolExecutor and returns None."""
         mock_llm = Mock()
@@ -682,49 +700,14 @@ class TestAgentIterationFeedback:
 
         agent = Agent(mock_llm, mock_executor, session)
 
-        with patch("ayder_cli.ui.draw_box") as mock_draw_box:
-            result = agent.chat("do something")
+        result = agent.chat("do something")
 
         assert result is None
         # Should have called LLM exactly 2 times (max_iterations=2)
         assert mock_llm.chat.call_count == 2
-        # Warning should be shown
-        mock_draw_box.assert_called_once()
-        assert "Reached maximum iterations" in mock_draw_box.call_args[0][0]
-
-    def test_verbose_iteration_counter_shown(self):
-        """Test that iteration counter is shown in verbose mode."""
-        mock_llm = Mock()
-        config = Config(
-            base_url="http://test.com",
-            api_key="test-key",
-            model="test-model",
-            num_ctx=4096,
-            verbose=True,
-        )
-        session = ChatSession(config, "prompt", iterations=2)
-        session.state["verbose"] = True
-
-        mock_executor = Mock()
-        mock_registry = Mock()
-        mock_registry.get_schemas.return_value = []
-        mock_executor.tool_registry = mock_registry
-        mock_executor.execute_tool_calls.return_value = False
-
-        mock_llm.chat.return_value = self._make_tool_response()
-
-        agent = Agent(mock_llm, mock_executor, session)
-
-        with patch("ayder_cli.ui.draw_box") as mock_draw_box:
-            agent.chat("do something")
-
-        # Should have 2 verbose calls + 1 warning = 3
-        calls = [call[0][0] for call in mock_draw_box.call_args_list]
-        assert any("Iteration 1/2" in c for c in calls)
-        assert any("Iteration 2/2" in c for c in calls)
 
     def test_no_warning_when_iterations_not_exhausted(self):
-        """Test that no warning is shown when agent finishes before limit."""
+        """Test that agent returns response when finishing before limit."""
         mock_llm = Mock()
         config = Config(
             base_url="http://test.com",
@@ -754,9 +737,7 @@ class TestAgentIterationFeedback:
 
         agent = Agent(mock_llm, mock_executor, session)
 
-        with patch("ayder_cli.ui.draw_box") as mock_draw_box:
-            result = agent.chat("hello")
+        result = agent.chat("hello")
 
         assert result == "Here is the answer"
-        mock_draw_box.assert_not_called()
 
diff --git a/tests/client/test_main.py b/tests/client/test_main.py
index 4417f46..35510f5 100644
--- a/tests/client/test_main.py
+++ b/tests/client/test_main.py
@@ -10,7 +10,7 @@ class TestMainEntryPoint:
 
     def test_main_calls_cli_main(self):
         """Test that running __main__ module calls cli.main()."""
-        with patch("ayder_cli.cli.run_interactive") as mock_run_interactive, \
+        with patch("ayder_cli.cli_runner.run_interactive") as mock_run_interactive, \
              patch("sys.argv", ["ayder"]), \
              patch("sys.stdin.isatty", return_value=True):
             # Run the module as __main__ using runpy
diff --git a/tests/commands/test_cli_file_stdin.py b/tests/commands/test_cli_file_stdin.py
index 02bd979..d1812b6 100644
--- a/tests/commands/test_cli_file_stdin.py
+++ b/tests/commands/test_cli_file_stdin.py
@@ -5,7 +5,8 @@ import pytest
 from unittest.mock import patch, MagicMock
 from io import StringIO
 
-from ayder_cli.cli import main, read_input, run_command
+from ayder_cli.cli import main, read_input
+from ayder_cli.cli_runner import run_command
 
 
 class TestReadInput:
@@ -103,7 +104,7 @@ class TestRunCommand:
              patch('ayder_cli.tools.registry.create_default_registry', return_value=mock_registry), \
              patch('openai.OpenAI'), \
              patch('builtins.print') as mock_print:
-            from ayder_cli.cli import run_command
+            from ayder_cli.cli_runner import run_command
             exit_code = run_command("test command")
             assert exit_code == 0
 
@@ -111,7 +112,7 @@ class TestRunCommand:
         """Test error handling in command execution."""
         with patch('ayder_cli.core.config.load_config', side_effect=Exception("Config error")), \
              patch('builtins.print'):
-            from ayder_cli.cli import run_command
+            from ayder_cli.cli_runner import run_command
             exit_code = run_command("test")
             assert exit_code == 1
 
@@ -144,6 +145,7 @@ class TestRunCommand:
              patch('openai.OpenAI'), \
              patch('builtins.print'):
             
+            from ayder_cli.cli_runner import run_command
             run_command("test")
             
             # Verify ProjectContext was initialized
diff --git a/tests/commands/test_registry.py b/tests/commands/test_registry.py
index 5770a28..8f1004f 100644
--- a/tests/commands/test_registry.py
+++ b/tests/commands/test_registry.py
@@ -60,3 +60,31 @@ class TestCommandRegistry:
                 return True
                 
         assert _registry.get_command("/decorated") is not None
+
+    def test_get_command_names(self):
+        """Test getting all command names."""
+        registry = CommandRegistry()
+        
+        # Register multiple commands
+        cmd1 = MockCommand()
+        registry.register(cmd1)
+        
+        class AnotherMockCommand(BaseCommand):
+            @property
+            def name(self):
+                return "/another"
+            
+            @property
+            def description(self):
+                return "Another mock"
+                
+            def execute(self, args, session):
+                return True
+        
+        cmd2 = AnotherMockCommand()
+        registry.register(cmd2)
+        
+        names = registry.get_command_names()
+        assert len(names) == 2
+        assert "/another" in names  # Sorted alphabetically
+        assert "/mock" in names
diff --git a/tests/commands/test_system_commands.py b/tests/commands/test_system_commands.py
index 8052810..bca9e8a 100644
--- a/tests/commands/test_system_commands.py
+++ b/tests/commands/test_system_commands.py
@@ -3,9 +3,12 @@
 import pytest
 from unittest.mock import Mock, patch
 from ayder_cli.commands.system import (
-    HelpCommand, ClearCommand, SummaryCommand, LoadCommand,
-    CompactCommand, VerboseCommand, PlanCommand, ModelCommand, AskCommand
+    HelpCommand, CompactCommand, VerboseCommand, PlanCommand, ModelCommand, AskCommand
 )
+
+# NOTE: ClearCommand, SummaryCommand, and LoadCommand are disabled.
+# They duplicate functionality that should be handled by MemoryManager.
+# Tests for these commands are commented out below.
 from ayder_cli.core.context import SessionContext, ProjectContext
 from ayder_cli.core.config import Config
 from ayder_cli.prompts import SYSTEM_PROMPT
@@ -45,79 +48,13 @@ class TestHelpCommand:
         assert "/test" in content
         assert "Test command" in content
 
-class TestClearCommand:
-    """Test /clear command."""
-
-    @patch("ayder_cli.commands.system.draw_box")
-    def test_clear_command(self, mock_draw_box):
-        """Test clear command resets messages and adds prompt."""
-        cmd = ClearCommand()
-        session = _create_session(
-            messages=[
-                {"role": "system", "content": "sys"},
-                {"role": "user", "content": "hi"}
-            ]
-        )
-        
-        result = cmd.execute("", session)
-        
-        assert result is True
-        assert len(session.messages) == 2  # system + reset prompt
-        assert session.messages[0]["content"] == "sys"
-        assert session.messages[1]["role"] == "user"
-        assert "cleared" in session.messages[1]["content"].lower()
-        mock_draw_box.assert_called_once()
-
-    @patch("ayder_cli.commands.system.draw_box")
-    def test_clear_command_empty(self, mock_draw_box):
-        """Test clear command with empty messages."""
-        cmd = ClearCommand()
-        session = _create_session(messages=[])
-        
-        result = cmd.execute("", session)
-        
-        assert result is True
-        assert len(session.messages) == 1  # just the reset prompt
-
-
-class TestSummaryCommand:
-    """Test /summary command."""
-
-    @patch("ayder_cli.commands.system.draw_box")
-    def test_summary_command_with_conversation(self, mock_draw_box):
-        """Test summary command adds prompt with conversation."""
-        from ayder_cli.commands.system import SummaryCommand
-        cmd = SummaryCommand()
-        session = _create_session(
-            messages=[
-                {"role": "system", "content": "sys"},
-                {"role": "user", "content": "hello"},
-                {"role": "assistant", "content": "hi there"}
-            ]
-        )
-        
-        result = cmd.execute("", session)
-        
-        assert result is True
-        # Should add a user message for the agent to process
-        assert len(session.messages) == 4
-        assert session.messages[-1]["role"] == "user"
-        assert "summarize" in session.messages[-1]["content"].lower()
-        mock_draw_box.assert_called_once()
-
-    @patch("ayder_cli.commands.system.draw_box")
-    def test_summary_command_no_conversation(self, mock_draw_box):
-        """Test summary command with no conversation."""
-        from ayder_cli.commands.system import SummaryCommand
-        cmd = SummaryCommand()
-        session = _create_session(messages=[{"role": "system", "content": "sys"}])
-        
-        result = cmd.execute("", session)
-        
-        assert result is True
-        assert len(session.messages) == 1
-        mock_draw_box.assert_called_once()
+# class TestClearCommand:
+#     """DISABLED: /clear command - use automatic checkpointing or /compact instead."""
+#     pass
 
+# class TestSummaryCommand:
+#     """DISABLED: /summary command - use automatic checkpointing or /compact instead."""
+#     pass
 
 class TestCompactCommand:
     """Test /compact command."""
@@ -160,21 +97,9 @@ class TestCompactCommand:
         mock_draw_box.assert_called_once()
 
 
-class TestLoadCommand:
-    """Test /load command."""
-
-    @patch("ayder_cli.commands.system.draw_box")
-    def test_load_command_file_not_found(self, mock_draw_box):
-        """Test load command when memory file doesn't exist."""
-        from ayder_cli.commands.system import LoadCommand
-        cmd = LoadCommand()
-        session = _create_session(messages=[])
-        
-        result = cmd.execute("", session)
-        
-        assert result is True
-        mock_draw_box.assert_called_once()
-        assert "not found" in mock_draw_box.call_args[0][0]
+# class TestLoadCommand:
+#     """DISABLED: /load command - use automatic checkpointing or /compact instead."""
+#     pass
 
 class TestVerboseCommand:
     """Test /verbose command."""
diff --git a/tests/test_cli.py b/tests/test_cli.py
index a5a1d0c..dd3e77e 100644
--- a/tests/test_cli.py
+++ b/tests/test_cli.py
@@ -11,7 +11,7 @@ class TestBuildServices:
 
     def test_build_services_with_exception_in_structure_macro(self):
         """Test that _build_services handles exception when getting project structure."""
-        from ayder_cli.cli import _build_services
+        from ayder_cli.cli_runner import _build_services
         from ayder_cli.core.config import Config
 
         mock_config = Config(
@@ -28,18 +28,21 @@ class TestBuildServices:
         with patch('ayder_cli.core.config.load_config', return_value=mock_config), \
              patch('ayder_cli.tools.registry.create_default_registry', return_value=mock_registry), \
              patch('openai.OpenAI'):
-            cfg, llm_provider, tool_executor, project_ctx, enhanced_system = _build_services()
+            services = _build_services()
+            cfg, llm_provider, tool_executor, project_ctx, enhanced_system, checkpoint_manager, memory_manager = services
 
             assert cfg == mock_config
             assert llm_provider is not None
             assert tool_executor is not None
             assert project_ctx is not None
+            assert checkpoint_manager is not None
+            assert memory_manager is not None
             # Verify macro is empty when exception occurs
             assert "PROJECT STRUCTURE" not in enhanced_system
 
     def test_build_services_success_with_structure_macro(self):
         """Test _build_services successfully adds structure macro."""
-        from ayder_cli.cli import _build_services
+        from ayder_cli.cli_runner import _build_services
         from ayder_cli.core.config import Config
 
         mock_config = Config(
@@ -56,15 +59,18 @@ class TestBuildServices:
         with patch('ayder_cli.core.config.load_config', return_value=mock_config), \
              patch('ayder_cli.tools.registry.create_default_registry', return_value=mock_registry), \
              patch('openai.OpenAI'):
-            cfg, llm_provider, tool_executor, project_ctx, enhanced_system = _build_services()
+            services = _build_services()
+            cfg, llm_provider, tool_executor, project_ctx, enhanced_system, checkpoint_manager, memory_manager = services
 
             assert "PROJECT STRUCTURE" in enhanced_system
             assert "src/" in enhanced_system
+            assert checkpoint_manager is not None
+            assert memory_manager is not None
             mock_registry.execute.assert_called_once_with("get_project_structure", {"max_depth": 3})
 
     def test_build_services_with_custom_config(self):
         """Test _build_services accepts custom config parameter."""
-        from ayder_cli.cli import _build_services
+        from ayder_cli.cli_runner import _build_services
         from ayder_cli.core.config import Config
 
         mock_config = Config(
@@ -80,14 +86,15 @@ class TestBuildServices:
 
         with patch('ayder_cli.tools.registry.create_default_registry', return_value=mock_registry), \
              patch('openai.OpenAI'):
-            cfg, _, _, _, _ = _build_services(config=mock_config)
+            services = _build_services(config=mock_config)
+            cfg = services[0]
 
             assert cfg == mock_config
             # load_config should NOT be called when config is provided
 
     def test_build_services_with_custom_project_root(self):
         """Test _build_services accepts custom project root."""
-        from ayder_cli.cli import _build_services
+        from ayder_cli.cli_runner import _build_services
         from ayder_cli.core.config import Config
 
         mock_config = Config(
@@ -172,19 +179,19 @@ class TestReadInput:
 class TestRunCommand:
     """Test run_command function."""
 
-    @patch('ayder_cli.cli._build_services')
+    @patch('ayder_cli.cli_runner._build_services')
     @patch('ayder_cli.client.ChatSession')
     @patch('ayder_cli.client.Agent')
     def test_run_command_success(self, mock_agent_class, mock_session_class, mock_build_services):
         """Test successful command execution."""
-        from ayder_cli.cli import run_command
+        from ayder_cli.cli_runner import run_command
 
         mock_config = MagicMock()
         mock_llm = MagicMock()
         mock_executor = MagicMock()
         mock_system = "system prompt"
 
-        mock_build_services.return_value = (mock_config, mock_llm, mock_executor, MagicMock(), mock_system)
+        mock_build_services.return_value = (mock_config, mock_llm, mock_executor, MagicMock(), mock_system, MagicMock(), MagicMock())
         
         mock_agent = MagicMock()
         mock_agent.chat.return_value = "Response text"
@@ -195,10 +202,10 @@ class TestRunCommand:
         assert result == 0
         mock_agent.chat.assert_called_once_with("test prompt")
 
-    @patch('ayder_cli.cli._build_services')
+    @patch('ayder_cli.cli_runner._build_services')
     def test_run_command_error(self, mock_build_services):
         """Test command execution with error."""
-        from ayder_cli.cli import run_command
+        from ayder_cli.cli_runner import run_command
 
         mock_build_services.side_effect = Exception("Build error")
 
@@ -207,14 +214,14 @@ class TestRunCommand:
             assert result == 1
             assert "Build error" in mock_stderr.getvalue()
 
-    @patch('ayder_cli.cli._build_services')
+    @patch('ayder_cli.cli_runner._build_services')
     @patch('ayder_cli.client.ChatSession')
     @patch('ayder_cli.client.Agent')
     def test_run_command_no_response(self, mock_agent_class, mock_session_class, mock_build_services):
         """Test command execution with no response."""
-        from ayder_cli.cli import run_command
+        from ayder_cli.cli_runner import run_command
 
-        mock_build_services.return_value = (MagicMock(), MagicMock(), MagicMock(), MagicMock(), "system")
+        mock_build_services.return_value = (MagicMock(), MagicMock(), MagicMock(), MagicMock(), "system", MagicMock(), MagicMock())
         
         mock_agent = MagicMock()
         mock_agent.chat.return_value = None
@@ -232,7 +239,7 @@ class TestRunTasksCLI:
     @patch('ayder_cli.tasks.list_tasks')
     def test_run_tasks_cli_success(self, mock_list_tasks, mock_project_ctx):
         """Test successful tasks listing."""
-        from ayder_cli.cli import _run_tasks_cli
+        from ayder_cli.cli_runner import _run_tasks_cli
 
         mock_list_tasks.return_value = "Task 1\nTask 2"
 
@@ -245,7 +252,7 @@ class TestRunTasksCLI:
     @patch('ayder_cli.tasks.list_tasks')
     def test_run_tasks_cli_error(self, mock_list_tasks, mock_project_ctx):
         """Test tasks listing with error."""
-        from ayder_cli.cli import _run_tasks_cli
+        from ayder_cli.cli_runner import _run_tasks_cli
 
         mock_list_tasks.side_effect = Exception("List error")
 
@@ -258,7 +265,7 @@ class TestRunTasksCLI:
 class TestRunImplementCLI:
     """Test _run_implement_cli function."""
 
-    @patch('ayder_cli.cli._build_services')
+    @patch('ayder_cli.cli_runner._build_services')
     @patch('ayder_cli.client.ChatSession')
     @patch('ayder_cli.client.Agent')
     @patch('ayder_cli.core.context.ProjectContext')
@@ -267,7 +274,7 @@ class TestRunImplementCLI:
     def test_run_implement_by_id_success(self, mock_get_path, mock_get_dir, mock_project_ctx,
                                           mock_agent_class, mock_session_class, mock_build_services):
         """Test implementing task by ID."""
-        from ayder_cli.cli import _run_implement_cli
+        from ayder_cli.cli_runner import _run_implement_cli
         from pathlib import Path
         import tempfile
 
@@ -280,7 +287,7 @@ class TestRunImplementCLI:
             mock_get_dir.return_value = tasks_dir
             mock_get_path.return_value = task_file
 
-            mock_build_services.return_value = (MagicMock(), MagicMock(), MagicMock(), MagicMock(), "system")
+            mock_build_services.return_value = (MagicMock(), MagicMock(), MagicMock(), MagicMock(), "system", MagicMock(), MagicMock())
             mock_agent = MagicMock()
             mock_agent.chat.return_value = "Task completed"
             mock_agent_class.return_value = mock_agent
@@ -291,7 +298,7 @@ class TestRunImplementCLI:
             assert result == 0
             mock_agent.chat.assert_called_once()
 
-    @patch('ayder_cli.cli._build_services')
+    @patch('ayder_cli.cli_runner._build_services')
     @patch('ayder_cli.client.ChatSession')
     @patch('ayder_cli.client.Agent')
     @patch('ayder_cli.core.context.ProjectContext')
@@ -302,7 +309,7 @@ class TestRunImplementCLI:
                                                mock_project_ctx, mock_agent_class, mock_session_class,
                                                mock_build_services):
         """Test implementing task by pattern match."""
-        from ayder_cli.cli import _run_implement_cli
+        from ayder_cli.cli_runner import _run_implement_cli
         from pathlib import Path
         import tempfile
 
@@ -316,7 +323,7 @@ class TestRunImplementCLI:
             mock_extract_id.return_value = 1
             mock_parse_title.return_value = "Implement Authentication"
 
-            mock_build_services.return_value = (MagicMock(), MagicMock(), MagicMock(), MagicMock(), "system")
+            mock_build_services.return_value = (MagicMock(), MagicMock(), MagicMock(), MagicMock(), "system", MagicMock(), MagicMock())
             mock_agent = MagicMock()
             mock_agent.chat.return_value = "Task completed"
             mock_agent_class.return_value = mock_agent
@@ -326,12 +333,12 @@ class TestRunImplementCLI:
 
             assert result == 0
 
-    @patch('ayder_cli.cli._build_services')
+    @patch('ayder_cli.cli_runner._build_services')
     @patch('ayder_cli.core.context.ProjectContext')
     @patch('ayder_cli.tasks._get_tasks_dir')
     def test_run_implement_no_match(self, mock_get_dir, mock_project_ctx, mock_build_services):
         """Test implementing when no task matches."""
-        from ayder_cli.cli import _run_implement_cli
+        from ayder_cli.cli_runner import _run_implement_cli
         from pathlib import Path
         import tempfile
 
@@ -340,17 +347,17 @@ class TestRunImplementCLI:
             tasks_dir.mkdir(parents=True)
 
             mock_get_dir.return_value = tasks_dir
-            mock_build_services.return_value = (MagicMock(), MagicMock(), MagicMock(), MagicMock(), "system")
+            mock_build_services.return_value = (MagicMock(), MagicMock(), MagicMock(), MagicMock(), "system", MagicMock(), MagicMock())
 
             with patch('sys.stderr', new=StringIO()) as mock_stderr:
                 result = _run_implement_cli("nonexistent", permissions={"r"})
                 assert result == 1
                 assert "No tasks found" in mock_stderr.getvalue()
 
-    @patch('ayder_cli.cli._build_services')
+    @patch('ayder_cli.cli_runner._build_services')
     def test_run_implement_error(self, mock_build_services):
         """Test implement with error."""
-        from ayder_cli.cli import _run_implement_cli
+        from ayder_cli.cli_runner import _run_implement_cli
 
         mock_build_services.side_effect = Exception("Build error")
 
@@ -363,14 +370,14 @@ class TestRunImplementCLI:
 class TestRunImplementAllCLI:
     """Test _run_implement_all_cli function."""
 
-    @patch('ayder_cli.cli._build_services')
+    @patch('ayder_cli.cli_runner._build_services')
     @patch('ayder_cli.client.ChatSession')
     @patch('ayder_cli.client.Agent')
     def test_run_implement_all_success(self, mock_agent_class, mock_session_class, mock_build_services):
         """Test successful implement all."""
-        from ayder_cli.cli import _run_implement_all_cli
+        from ayder_cli.cli_runner import _run_implement_all_cli
 
-        mock_build_services.return_value = (MagicMock(), MagicMock(), MagicMock(), MagicMock(), "system")
+        mock_build_services.return_value = (MagicMock(), MagicMock(), MagicMock(), MagicMock(), "system", MagicMock(), MagicMock())
         mock_agent = MagicMock()
         mock_agent.chat.return_value = "All tasks completed"
         mock_agent_class.return_value = mock_agent
@@ -381,10 +388,10 @@ class TestRunImplementAllCLI:
         assert result == 0
         mock_agent.chat.assert_called_once()
 
-    @patch('ayder_cli.cli._build_services')
+    @patch('ayder_cli.cli_runner._build_services')
     def test_run_implement_all_error(self, mock_build_services):
         """Test implement all with error."""
-        from ayder_cli.cli import _run_implement_all_cli
+        from ayder_cli.cli_runner import _run_implement_all_cli
 
         mock_build_services.side_effect = Exception("Build error")
 
@@ -399,7 +406,7 @@ class TestRunInteractive:
 
     def test_run_interactive_basic_input(self):
         """Test basic input handling in interactive mode."""
-        from ayder_cli.cli import run_interactive
+        from ayder_cli.cli_runner import run_interactive
 
         mock_session = MagicMock()
         mock_session.get_input.side_effect = ["hello", None]  # One input then exit
@@ -410,8 +417,8 @@ class TestRunInteractive:
         mock_config = MagicMock()
         mock_config.iterations = 10
 
-        with patch('ayder_cli.cli._build_services', return_value=(
-            mock_config, MagicMock(), MagicMock(), MagicMock(), "system prompt"
+        with patch('ayder_cli.cli_runner._build_services', return_value=(
+            mock_config, MagicMock(), MagicMock(), MagicMock(), "system prompt", MagicMock(), MagicMock()
         )), \
              patch('ayder_cli.client.ChatSession', return_value=mock_session), \
              patch('ayder_cli.client.Agent', return_value=mock_agent), \
@@ -425,7 +432,7 @@ class TestRunInteractive:
 
     def test_run_interactive_handles_slash_commands(self):
         """Test that slash commands are dispatched correctly."""
-        from ayder_cli.cli import run_interactive
+        from ayder_cli.cli_runner import run_interactive
 
         mock_session = MagicMock()
         mock_session.get_input.side_effect = ["/help", None]
@@ -436,8 +443,8 @@ class TestRunInteractive:
         mock_config = MagicMock()
         mock_project_ctx = MagicMock()
 
-        with patch('ayder_cli.cli._build_services', return_value=(
-            mock_config, MagicMock(), MagicMock(), mock_project_ctx, "system prompt"
+        with patch('ayder_cli.cli_runner._build_services', return_value=(
+            mock_config, MagicMock(), MagicMock(), mock_project_ctx, "system prompt", MagicMock(), MagicMock()
         )), \
              patch('ayder_cli.client.ChatSession', return_value=mock_session), \
              patch('ayder_cli.client.Agent', return_value=mock_agent), \
@@ -454,7 +461,7 @@ class TestRunInteractive:
 
     def test_run_interactive_slash_command_adds_message(self):
         """Test that slash command adding message triggers agent processing."""
-        from ayder_cli.cli import run_interactive
+        from ayder_cli.cli_runner import run_interactive
 
         mock_session = MagicMock()
         mock_session.get_input.side_effect = ["/implement 1", None]
@@ -469,8 +476,8 @@ class TestRunInteractive:
             mock_session.messages.append({"role": "user", "content": "Implement task"})
             return True
 
-        with patch('ayder_cli.cli._build_services', return_value=(
-            mock_config, MagicMock(), MagicMock(), MagicMock(), "system prompt"
+        with patch('ayder_cli.cli_runner._build_services', return_value=(
+            mock_config, MagicMock(), MagicMock(), MagicMock(), "system prompt", MagicMock(), MagicMock()
         )), \
              patch('ayder_cli.client.ChatSession', return_value=mock_session), \
              patch('ayder_cli.client.Agent', return_value=mock_agent), \
@@ -486,7 +493,7 @@ class TestRunInteractive:
 
     def test_run_interactive_slash_command_error(self):
         """Test error handling when processing slash command message."""
-        from ayder_cli.cli import run_interactive
+        from ayder_cli.cli_runner import run_interactive
 
         mock_session = MagicMock()
         mock_session.get_input.side_effect = ["/implement 1", None]
@@ -500,8 +507,8 @@ class TestRunInteractive:
             mock_session.messages.append({"role": "user", "content": "Implement task"})
             return True
 
-        with patch('ayder_cli.cli._build_services', return_value=(
-            mock_config, MagicMock(), MagicMock(), MagicMock(), "system prompt"
+        with patch('ayder_cli.cli_runner._build_services', return_value=(
+            mock_config, MagicMock(), MagicMock(), MagicMock(), "system prompt", MagicMock(), MagicMock()
         )), \
              patch('ayder_cli.client.ChatSession', return_value=mock_session), \
              patch('ayder_cli.client.Agent', return_value=mock_agent), \
@@ -516,7 +523,7 @@ class TestRunInteractive:
 
     def test_run_interactive_empty_input_continues(self):
         """Test that empty input continues the loop."""
-        from ayder_cli.cli import run_interactive
+        from ayder_cli.cli_runner import run_interactive
 
         mock_session = MagicMock()
         # Empty string should be skipped, then exit
@@ -525,8 +532,8 @@ class TestRunInteractive:
         mock_agent = MagicMock()
         mock_config = MagicMock()
 
-        with patch('ayder_cli.cli._build_services', return_value=(
-            mock_config, MagicMock(), MagicMock(), MagicMock(), "system prompt"
+        with patch('ayder_cli.cli_runner._build_services', return_value=(
+            mock_config, MagicMock(), MagicMock(), MagicMock(), "system prompt", MagicMock(), MagicMock()
         )), \
              patch('ayder_cli.client.ChatSession', return_value=mock_session), \
              patch('ayder_cli.client.Agent', return_value=mock_agent), \
@@ -539,7 +546,7 @@ class TestRunInteractive:
 
     def test_run_interactive_error_handling(self):
         """Test error handling in interactive mode."""
-        from ayder_cli.cli import run_interactive
+        from ayder_cli.cli_runner import run_interactive
 
         mock_session = MagicMock()
         mock_session.get_input.side_effect = ["trigger error", None]
@@ -549,8 +556,8 @@ class TestRunInteractive:
 
         mock_config = MagicMock()
 
-        with patch('ayder_cli.cli._build_services', return_value=(
-            mock_config, MagicMock(), MagicMock(), MagicMock(), "system prompt"
+        with patch('ayder_cli.cli_runner._build_services', return_value=(
+            mock_config, MagicMock(), MagicMock(), MagicMock(), "system prompt", MagicMock(), MagicMock()
         )), \
              patch('ayder_cli.client.ChatSession', return_value=mock_session), \
              patch('ayder_cli.client.Agent', return_value=mock_agent), \
@@ -565,7 +572,7 @@ class TestRunInteractive:
 
     def test_run_interactive_multiple_messages(self):
         """Test multiple messages in interactive session."""
-        from ayder_cli.cli import run_interactive
+        from ayder_cli.cli_runner import run_interactive
 
         mock_session = MagicMock()
         mock_session.get_input.side_effect = ["msg1", "msg2", None]
@@ -575,8 +582,8 @@ class TestRunInteractive:
 
         mock_config = MagicMock()
 
-        with patch('ayder_cli.cli._build_services', return_value=(
-            mock_config, MagicMock(), MagicMock(), MagicMock(), "system prompt"
+        with patch('ayder_cli.cli_runner._build_services', return_value=(
+            mock_config, MagicMock(), MagicMock(), MagicMock(), "system prompt", MagicMock(), MagicMock()
         )), \
              patch('ayder_cli.client.ChatSession', return_value=mock_session), \
              patch('ayder_cli.client.Agent', return_value=mock_agent), \
@@ -590,7 +597,7 @@ class TestRunInteractive:
 
     def test_run_interactive_session_start_called(self):
         """Test that session.start() is called on initialization."""
-        from ayder_cli.cli import run_interactive
+        from ayder_cli.cli_runner import run_interactive
 
         mock_session = MagicMock()
         mock_session.get_input.side_effect = [None]
@@ -598,8 +605,8 @@ class TestRunInteractive:
 
         mock_config = MagicMock()
 
-        with patch('ayder_cli.cli._build_services', return_value=(
-            mock_config, MagicMock(), MagicMock(), MagicMock(), "system prompt"
+        with patch('ayder_cli.cli_runner._build_services', return_value=(
+            mock_config, MagicMock(), MagicMock(), MagicMock(), "system prompt", MagicMock(), MagicMock()
         )), \
              patch('ayder_cli.client.ChatSession', return_value=mock_session), \
              patch('ayder_cli.client.Agent'):
@@ -653,7 +660,7 @@ class TestMainPermissionHandling:
         with patch.object(sys, 'argv', ['ayder', '-w', 'write something']), \
              patch.object(sys.stdin, 'isatty', return_value=True), \
              patch('ayder_cli.core.config.load_config', return_value=mock_config), \
-             patch('ayder_cli.cli.run_command', return_value=0) as mock_run, \
+             patch('ayder_cli.cli_runner.run_command', return_value=0) as mock_run, \
              patch('sys.exit'):
             
             main()
@@ -679,7 +686,7 @@ class TestMainPermissionHandling:
         with patch.object(sys, 'argv', ['ayder', '-x', 'run command']), \
              patch.object(sys.stdin, 'isatty', return_value=True), \
              patch('ayder_cli.core.config.load_config', return_value=mock_config), \
-             patch('ayder_cli.cli.run_command', return_value=0) as mock_run, \
+             patch('ayder_cli.cli_runner.run_command', return_value=0) as mock_run, \
              patch('sys.exit'):
             
             main()
@@ -705,7 +712,7 @@ class TestMainPermissionHandling:
         with patch.object(sys, 'argv', ['ayder', '-w', '-x', 'do something']), \
              patch.object(sys.stdin, 'isatty', return_value=True), \
              patch('ayder_cli.core.config.load_config', return_value=mock_config), \
-             patch('ayder_cli.cli.run_command', return_value=0) as mock_run, \
+             patch('ayder_cli.cli_runner.run_command', return_value=0) as mock_run, \
              patch('sys.exit'):
             
             main()
@@ -732,7 +739,7 @@ class TestMainPermissionHandling:
         with patch.object(sys, 'argv', ['ayder', 'hello']), \
              patch.object(sys.stdin, 'isatty', return_value=True), \
              patch('ayder_cli.core.config.load_config', return_value=mock_config), \
-             patch('ayder_cli.cli.run_command', return_value=0) as mock_run, \
+             patch('ayder_cli.cli_runner.run_command', return_value=0) as mock_run, \
              patch('sys.exit'):
             
             main()
@@ -761,7 +768,7 @@ class TestMainTaskOptions:
         with patch.object(sys, 'argv', ['ayder', '--tasks']), \
              patch.object(sys.stdin, 'isatty', return_value=True), \
              patch('ayder_cli.core.config.load_config', return_value=mock_config), \
-             patch('ayder_cli.cli._run_tasks_cli', return_value=0) as mock_run_tasks, \
+             patch('ayder_cli.cli_runner._run_tasks_cli', return_value=0) as mock_run_tasks, \
              patch('sys.exit') as mock_exit:
             
             main()
@@ -785,7 +792,7 @@ class TestMainTaskOptions:
         with patch.object(sys, 'argv', ['ayder', '--implement', '1']), \
              patch.object(sys.stdin, 'isatty', return_value=True), \
              patch('ayder_cli.core.config.load_config', return_value=mock_config), \
-             patch('ayder_cli.cli._run_implement_cli', return_value=0) as mock_run_implement, \
+             patch('ayder_cli.cli_runner._run_implement_cli', return_value=0) as mock_run_implement, \
              patch('sys.exit') as mock_exit:
             
             main()
@@ -809,7 +816,7 @@ class TestMainTaskOptions:
         with patch.object(sys, 'argv', ['ayder', '--implement-all']), \
              patch.object(sys.stdin, 'isatty', return_value=True), \
              patch('ayder_cli.core.config.load_config', return_value=mock_config), \
-             patch('ayder_cli.cli._run_implement_all_cli', return_value=0) as mock_run_all, \
+             patch('ayder_cli.cli_runner._run_implement_all_cli', return_value=0) as mock_run_all, \
              patch('sys.exit') as mock_exit:
             
             main()
@@ -872,7 +879,7 @@ class TestMainTUIAndInteractive:
              patch.object(sys.stdin, 'isatty', return_value=False), \
              patch('ayder_cli.core.config.load_config', return_value=mock_config), \
              patch('sys.stdin.read', return_value="Piped input"), \
-             patch('ayder_cli.cli.run_command', return_value=0) as mock_run, \
+             patch('ayder_cli.cli_runner.run_command', return_value=0) as mock_run, \
              patch('sys.exit'):
             
             main()
@@ -897,7 +904,7 @@ class TestMainTUIAndInteractive:
         with patch.object(sys, 'argv', ['ayder']), \
              patch.object(sys.stdin, 'isatty', return_value=True), \
              patch('ayder_cli.core.config.load_config', return_value=mock_config), \
-             patch('ayder_cli.cli.run_interactive') as mock_run_interactive:
+             patch('ayder_cli.cli_runner.run_interactive') as mock_run_interactive:
             
             main()
             
@@ -1015,7 +1022,7 @@ class TestCreateParser:
         with patch.object(sys, 'argv', ['ayder', 'hello world']), \
              patch.object(sys.stdin, 'isatty', return_value=True), \
              patch('ayder_cli.core.config.load_config', return_value=mock_config), \
-             patch('ayder_cli.cli.run_command', return_value=0) as mock_run, \
+             patch('ayder_cli.cli_runner.run_command', return_value=0) as mock_run, \
              patch('sys.exit'):
             main()
             mock_run.assert_called_once_with('hello world', permissions={'r'}, iterations=75)
@@ -1037,7 +1044,7 @@ class TestCreateParser:
         with patch.object(sys, 'argv', ['ayder', '-I', '20', 'hello']), \
              patch.object(sys.stdin, 'isatty', return_value=True), \
              patch('ayder_cli.core.config.load_config', return_value=mock_config), \
-             patch('ayder_cli.cli.run_command', return_value=0) as mock_run, \
+             patch('ayder_cli.cli_runner.run_command', return_value=0) as mock_run, \
              patch('sys.exit'):
             main()
             # CLI flag (20) should win over config (75)
diff --git a/tests/test_memory.py b/tests/test_memory.py
index c9d1aad..0390dec 100644
--- a/tests/test_memory.py
+++ b/tests/test_memory.py
@@ -3,7 +3,9 @@
 import json
 import pytest
 from pathlib import Path
-from ayder_cli.memory import save_memory, load_memory
+from unittest.mock import Mock, MagicMock, patch
+
+from ayder_cli.memory import save_memory, load_memory, MemoryManager, create_memory_manager
 from ayder_cli.core.context import ProjectContext
 from ayder_cli.core.result import ToolSuccess, ToolError
 
@@ -120,3 +122,223 @@ class TestLoadMemory:
         result = load_memory(project_context, query="postgresql")
         memories = json.loads(result)
         assert len(memories) == 1
+
+
+class TestMemoryManager:
+    """Test MemoryManager class for LLM-based checkpoint operations."""
+
+    @pytest.fixture
+    def memory_manager(self, tmp_path):
+        """Create a MemoryManager with mocked dependencies."""
+        project_ctx = ProjectContext(str(tmp_path))
+        llm = Mock()
+        tool_executor = Mock()
+        cm = Mock()
+        return MemoryManager(project_ctx, llm, tool_executor, cm)
+
+    def test_initialization(self, tmp_path):
+        """Test MemoryManager initialization."""
+        project_ctx = ProjectContext(str(tmp_path))
+        llm = Mock()
+        tool_executor = Mock()
+        cm = Mock()
+        
+        mm = MemoryManager(project_ctx, llm, tool_executor, cm)
+        
+        assert mm.project_ctx == project_ctx
+        assert mm.llm == llm
+        assert mm.tool_executor == tool_executor
+        assert mm.cm == cm
+        assert mm._cycle_count == 0
+
+    def test_initialization_without_optional_deps(self, tmp_path):
+        """Test MemoryManager initialization without optional dependencies."""
+        project_ctx = ProjectContext(str(tmp_path))
+        
+        mm = MemoryManager(project_ctx)
+        
+        assert mm.llm is None
+        assert mm.tool_executor is None
+        assert mm.cm is None
+
+    def test_build_checkpoint_prompt(self, memory_manager):
+        """Test building checkpoint prompt."""
+        summary = "Test conversation summary"
+        prompt = memory_manager.build_checkpoint_prompt(summary)
+        
+        assert "Test conversation summary" in prompt
+        assert "write_file" in prompt or "checkpoint" in prompt.lower()
+
+    def test_build_restore_prompt(self, memory_manager, tmp_path):
+        """Test building restore prompt."""
+        # Create a checkpoint file
+        checkpoint_file = tmp_path / ".ayder" / "memory" / "current_memory.md"
+        checkpoint_file.parent.mkdir(parents=True, exist_ok=True)
+        checkpoint_file.write_text("Saved checkpoint content")
+        
+        # Update memory manager's checkpoint file path
+        memory_manager._checkpoint_file = checkpoint_file
+        
+        prompt = memory_manager.build_restore_prompt()
+        
+        assert "Saved checkpoint content" in prompt
+        assert "current_memory.md" in prompt
+
+    def test_build_restore_prompt_with_content(self, memory_manager):
+        """Test building restore prompt with provided content."""
+        content = "Custom checkpoint content"
+        prompt = memory_manager.build_restore_prompt(content)
+        
+        assert "Custom checkpoint content" in prompt
+
+    def test_build_quick_restore_message_with_checkpoint(self, memory_manager, tmp_path):
+        """Test building quick restore message when checkpoint exists."""
+        # Create a checkpoint file
+        checkpoint_file = tmp_path / ".ayder" / "memory" / "current_memory.md"
+        checkpoint_file.parent.mkdir(parents=True, exist_ok=True)
+        checkpoint_file.write_text("Checkpoint data")
+        
+        memory_manager._checkpoint_file = checkpoint_file
+        
+        message = memory_manager.build_quick_restore_message()
+        
+        assert "Checkpoint data" in message
+        assert "SYSTEM: Context reset completed" in message
+
+    def test_build_quick_restore_message_no_checkpoint(self, memory_manager):
+        """Test building quick restore message when no checkpoint exists."""
+        message = memory_manager.build_quick_restore_message()
+        
+        assert "No previous memory" in message or "Continuing task" in message
+
+    def test_create_checkpoint_no_llm(self, memory_manager):
+        """Test create_checkpoint returns False when no LLM."""
+        memory_manager.llm = None
+        session = Mock()
+        
+        result = memory_manager.create_checkpoint(session, "model", 4096, set(), False)
+        
+        assert result is False
+
+    def test_create_checkpoint_no_tool_executor(self, memory_manager):
+        """Test create_checkpoint returns False when no tool executor."""
+        memory_manager.tool_executor = None
+        session = Mock()
+        
+        result = memory_manager.create_checkpoint(session, "model", 4096, set(), False)
+        
+        assert result is False
+
+    def test_create_checkpoint_success(self, memory_manager):
+        """Test successful checkpoint creation."""
+        session = Mock()
+        session.get_messages.return_value = [
+            {"role": "user", "content": "Hello"},
+            {"role": "assistant", "content": "Hi there"},
+        ]
+        
+        # Mock LLM response
+        mock_message = Mock()
+        mock_message.content = "Checkpoint saved"
+        mock_message.tool_calls = None
+        
+        mock_choice = Mock()
+        mock_choice.message = mock_message
+        
+        mock_response = Mock()
+        mock_response.choices = [mock_choice]
+        
+        memory_manager.llm.chat.return_value = mock_response
+        memory_manager.tool_executor.tool_registry = Mock()
+        memory_manager.tool_executor.tool_registry.get_schemas.return_value = []
+        
+        result = memory_manager.create_checkpoint(session, "model", 4096, set(), False)
+        
+        assert result is True
+        assert memory_manager._cycle_count == 1
+        session.add_message.assert_called()
+        session.clear_messages.assert_called_once_with(keep_system=True)
+
+    def test_create_checkpoint_with_tool_calls(self, memory_manager):
+        """Test checkpoint creation when LLM makes tool calls."""
+        session = Mock()
+        session.get_messages.return_value = []
+        
+        # Mock LLM response with tool calls
+        mock_tool_call = Mock()
+        mock_message = Mock()
+        mock_message.content = None
+        mock_message.tool_calls = [mock_tool_call]
+        
+        mock_choice = Mock()
+        mock_choice.message = mock_message
+        
+        mock_response = Mock()
+        mock_response.choices = [mock_choice]
+        
+        memory_manager.llm.chat.return_value = mock_response
+        memory_manager.tool_executor.tool_registry = Mock()
+        memory_manager.tool_executor.tool_registry.get_schemas.return_value = []
+        memory_manager.tool_executor.execute_tool_calls = Mock()
+        
+        result = memory_manager.create_checkpoint(session, "model", 4096, set(), False)
+        
+        assert result is True
+        session.append_raw.assert_called_once_with(mock_message)
+        memory_manager.tool_executor.execute_tool_calls.assert_called_once()
+
+    def test_restore_from_checkpoint(self, memory_manager):
+        """Test restore_from_checkpoint."""
+        session = Mock()
+        
+        # Mock _read_checkpoint to return content
+        memory_manager._read_checkpoint = Mock(return_value="Saved memory content")
+        
+        memory_manager.restore_from_checkpoint(session)
+        
+        session.clear_messages.assert_called_once_with(keep_system=True)
+        session.add_message.assert_called_once()
+
+    def test_build_conversation_summary(self, memory_manager):
+        """Test building conversation summary."""
+        session = Mock()
+        session.get_messages.return_value = [
+            {"role": "user", "content": "Hello world, this is a test message"},
+            {"role": "assistant", "content": "Hi there, I can help you"},
+        ]
+        
+        summary = memory_manager._build_conversation_summary(session)
+        
+        assert "[user]" in summary
+        assert "[assistant]" in summary
+        assert "Hello world" in summary
+
+    def test_read_checkpoint(self, memory_manager, tmp_path):
+        """Test reading checkpoint file."""
+        # Create a checkpoint file
+        checkpoint_file = tmp_path / ".ayder" / "memory" / "current_memory.md"
+        checkpoint_file.parent.mkdir(parents=True, exist_ok=True)
+        checkpoint_file.write_text("Test checkpoint data")
+        
+        memory_manager._checkpoint_file = checkpoint_file
+        
+        content = memory_manager._read_checkpoint()
+        
+        assert content == "Test checkpoint data"
+
+    def test_read_checkpoint_no_file(self, memory_manager):
+        """Test reading checkpoint when file doesn't exist."""
+        content = memory_manager._read_checkpoint()
+        
+        assert content is None
+
+
+class TestCreateMemoryManager:
+    """Test create_memory_manager factory function."""
+
+    def test_factory_creates_memory_manager(self, tmp_path):
+        """Test that factory creates a MemoryManager."""
+        mm = create_memory_manager(str(tmp_path))
+        
+        assert isinstance(mm, MemoryManager)
+        assert mm.project_ctx.root == tmp_path
diff --git a/tests/ui/test_cli_tui.py b/tests/ui/test_cli_tui.py
index 77e6a10..ab03929 100644
--- a/tests/ui/test_cli_tui.py
+++ b/tests/ui/test_cli_tui.py
@@ -45,7 +45,7 @@ def test_tui_with_command_error_message():
 def test_no_tui_flag_does_not_call_run_tui():
     """Test that without --tui flag, run_tui() is not called."""
     with patch('ayder_cli.tui.run_tui') as mock_run_tui, \
-         patch('ayder_cli.cli.run_interactive') as mock_run_interactive, \
+         patch('ayder_cli.cli_runner.run_interactive') as mock_run_interactive, \
          patch.object(sys, 'argv', ['ayder']), \
          patch.object(sys.stdin, 'isatty', return_value=True):
         from ayder_cli.cli import main
@@ -57,7 +57,7 @@ def test_no_tui_flag_does_not_call_run_tui():
 def test_tui_flag_exits_before_run_interactive():
     """Test that --tui returns before calling run_interactive()."""
     with patch('ayder_cli.tui.run_tui') as mock_run_tui, \
-         patch('ayder_cli.cli.run_interactive') as mock_run_interactive, \
+         patch('ayder_cli.cli_runner.run_interactive') as mock_run_interactive, \
          patch.object(sys, 'argv', ['ayder', '--tui']):
         from ayder_cli.cli import main
         main()
